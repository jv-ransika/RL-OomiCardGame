{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3cdf95b",
   "metadata": {
    "_cell_guid": "65e7fbe7-f82a-42f9-9107-005057b6fb65",
    "_uuid": "5aeea7a8-15a8-4308-b8bf-af96b3364437",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-07-11T06:31:20.770164Z",
     "iopub.status.busy": "2024-07-11T06:31:20.769475Z",
     "iopub.status.idle": "2024-07-11T06:31:24.950198Z",
     "shell.execute_reply": "2024-07-11T06:31:24.949391Z"
    },
    "executionInfo": {
     "elapsed": 4089,
     "status": "ok",
     "timestamp": 1720234044729,
     "user": {
      "displayName": "J. V. G. Ransika",
      "userId": "13058150827256079313"
     },
     "user_tz": -330
    },
    "id": "vm-wEyBE-1OG",
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 4.192365,
     "end_time": "2024-07-11T06:31:24.952708",
     "exception": false,
     "start_time": "2024-07-11T06:31:20.760343",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "import csv\n",
    "\n",
    "torch.set_default_device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5964f214",
   "metadata": {
    "_cell_guid": "998e9fb7-2f1d-44c3-841d-b529b1720f89",
    "_uuid": "b75f4956-51bc-4588-8715-20f3e5278bd9",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-07-11T06:31:24.966303Z",
     "iopub.status.busy": "2024-07-11T06:31:24.965939Z",
     "iopub.status.idle": "2024-07-11T06:31:24.978972Z",
     "shell.execute_reply": "2024-07-11T06:31:24.978183Z"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1720234044729,
     "user": {
      "displayName": "J. V. G. Ransika",
      "userId": "13058150827256079313"
     },
     "user_tz": -330
    },
    "id": "YVW2me6t-1OI",
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.021737,
     "end_time": "2024-07-11T06:31:24.980867",
     "exception": false,
     "start_time": "2024-07-11T06:31:24.959130",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PolicyNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, output_dim=32, dropout=0.5):\n",
    "        super(PolicyNetwork, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True, dropout=dropout, bidirectional=True)\n",
    "        self.fc1 = nn.Linear(hidden_dim * 2, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.layer_norm = nn.LayerNorm(hidden_dim * 2)\n",
    "\n",
    "    def forward(self, x, hidden, available_cards_mask=None):\n",
    "        out, hidden = self.lstm(x, hidden)\n",
    "        out = self.layer_norm(out[:, -1, :])\n",
    "        out = self.dropout(torch.relu(self.fc1(out)))\n",
    "        logits = self.fc2(out)\n",
    "\n",
    "        if available_cards_mask is not None:\n",
    "            logits = logits.masked_fill(~available_cards_mask, float('-inf'))\n",
    "\n",
    "        return F.softmax(logits, dim=-1), hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        return (torch.zeros(2 * self.lstm.num_layers, batch_size, self.lstm.hidden_size),\n",
    "                torch.zeros(2 * self.lstm.num_layers, batch_size, self.lstm.hidden_size))\n",
    "\n",
    "class ValueNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, dropout=0.5):\n",
    "        super(ValueNetwork, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_dim, 1)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        out, hidden = self.lstm(x, hidden)\n",
    "        out = self.dropout(out[:, -1, :])\n",
    "        value = self.fc(out)\n",
    "        return value, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        return (torch.zeros(self.lstm.num_layers, batch_size, self.lstm.hidden_size),\n",
    "                torch.zeros(self.lstm.num_layers, batch_size, self.lstm.hidden_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "491a16f3",
   "metadata": {
    "_cell_guid": "c8a2ddbe-4833-4b2b-95e5-e7b679df4e83",
    "_uuid": "d5d56667-b662-4425-ac66-2226c10e694b",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-07-11T06:31:24.993492Z",
     "iopub.status.busy": "2024-07-11T06:31:24.993226Z",
     "iopub.status.idle": "2024-07-11T06:31:24.999346Z",
     "shell.execute_reply": "2024-07-11T06:31:24.998532Z"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1720234044730,
     "user": {
      "displayName": "J. V. G. Ransika",
      "userId": "13058150827256079313"
     },
     "user_tz": -330
    },
    "id": "I9fWKXmg-1OJ",
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.014565,
     "end_time": "2024-07-11T06:31:25.001188",
     "exception": false,
     "start_time": "2024-07-11T06:31:24.986623",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "SUITES = ['H','D','C','S']\n",
    "\n",
    "RANKS = ['6', '7', '8', '9', 'J', 'Q', 'K', 'A']\n",
    "\n",
    "CARDS = [f'{a}{r}' for a in SUITES for r in RANKS]\n",
    "\n",
    "def sym_to_cat(symbol, d):\n",
    "    return [1 if s in symbol else 0 for s in d]\n",
    "\n",
    "def input_arr(alpha, c_hand, hand, desk_my, desk_enemy):\n",
    "    return np.array(sym_to_cat(alpha, SUITES) + sym_to_cat(c_hand, SUITES) + sym_to_cat(hand, CARDS) + sym_to_cat(desk_my, CARDS) + sym_to_cat(desk_enemy, CARDS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25048bc7",
   "metadata": {
    "_cell_guid": "2afcaee6-0fec-40ad-a717-22f02f95c1e3",
    "_uuid": "0b14419d-49d8-48a2-9ef3-25dec324da02",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-07-11T06:31:25.014288Z",
     "iopub.status.busy": "2024-07-11T06:31:25.014025Z",
     "iopub.status.idle": "2024-07-11T06:31:25.033252Z",
     "shell.execute_reply": "2024-07-11T06:31:25.032462Z"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1720234044730,
     "user": {
      "displayName": "J. V. G. Ransika",
      "userId": "13058150827256079313"
     },
     "user_tz": -330
    },
    "id": "sYBr03nl-1OJ",
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.027949,
     "end_time": "2024-07-11T06:31:25.035136",
     "exception": false,
     "start_time": "2024-07-11T06:31:25.007187",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the game environment (stub example)\n",
    "class OomiEnvironment:\n",
    "    def __init__(self, policy_net, value_net):\n",
    "        self.players = []\n",
    "        self.desk = [0] * 4\n",
    "        self.p_rewards = [0] * 4\n",
    "        self.c_player = None\n",
    "        self.cards = CARDS.copy()\n",
    "        self.trump = np.random.choice(SUITES)\n",
    "        self.hand = 'z'\n",
    "        self.team_score = [0] * 2\n",
    "\n",
    "        for i in range(4):\n",
    "            self.players.append(Player(self, policy_net, value_net, i%2, i))\n",
    "\n",
    "    def reset_round(self):\n",
    "        self.hand = 'z'\n",
    "        self.desk = [0] * 4\n",
    "        self.p_rewards = [0] * 4\n",
    "\n",
    "\n",
    "    def reset(self):\n",
    "        self.deal_cards()\n",
    "        self.desk = [0] * 4\n",
    "        self.p_rewards = [0] * 4\n",
    "        self.c_player = None\n",
    "        self.hand = 'z'\n",
    "        for player in self.players:\n",
    "            player.reset_hidden()\n",
    "\n",
    "        return self.desk\n",
    "\n",
    "    def desk_winner(self):\n",
    "        values = [self.card_to_val(card, self.trump) for card in self.desk]\n",
    "        max_value = max(values)\n",
    "\n",
    "        return values.index(max_value)\n",
    "\n",
    "    def prep_rewards(self, rewards):\n",
    "        ret = []\n",
    "        for i, r in enumerate(self.p_rewards):\n",
    "            ret.append([l + r for l in rewards[i]])\n",
    "\n",
    "        self.p_rewards = [0] * 4\n",
    "        return ret\n",
    "\n",
    "    def next_player(self):\n",
    "        if self.c_player is None or self.c_player == 3:\n",
    "            self.c_player = 0\n",
    "        else:\n",
    "            self.c_player += 1\n",
    "\n",
    "        return self.c_player\n",
    "\n",
    "    def deal_cards(self):\n",
    "        random.shuffle(self.cards)\n",
    "        for i in range(4):\n",
    "            self.players[i].actions = self.cards[i*8:(i+1)*8]\n",
    "\n",
    "    def card_to_val(self, card, alpha):\n",
    "        v = CARDS.index(card) % 8\n",
    "\n",
    "        if alpha in card:\n",
    "            v += 16\n",
    "        elif self.hand in card:\n",
    "            v += 8\n",
    "\n",
    "        return v\n",
    "\n",
    "    def step(self, action, player_id):\n",
    "        if action not in self.players[player_id].actions:\n",
    "            return self.desk, -10, False, False\n",
    "\n",
    "        # Penalize if the action card has already been played in this round\n",
    "#         if any(self.card_to_val(card, self.alpha, self.players[player_id].actions) == self.card_to_val(action, self.alpha, self.players[player_id].actions) for card in self.desk):\n",
    "#             return self.state, -2, False\n",
    "\n",
    "        if self.desk == [0, 0, 0, 0]:\n",
    "            self.hand = action[0]\n",
    "        else:\n",
    "            if self.hand != action[0]:\n",
    "                if any(self.hand in a for a in self.players[player_id].actions):\n",
    "                    return self.desk, -10, False, False\n",
    "        self.desk[player_id] = action\n",
    "        self.players[player_id].actions.remove(action)\n",
    "\n",
    "        if 0 not in self.desk:\n",
    "            winner = self.desk_winner()\n",
    "            self.p_rewards[winner] += 1\n",
    "            if winner%2==0:\n",
    "                self.p_rewards[0] += 1\n",
    "                self.p_rewards[2] += 1\n",
    "                self.team_score[0] += 1\n",
    "            else:\n",
    "                self.p_rewards[1] += 1\n",
    "                self.p_rewards[3] += 1\n",
    "                self.team_score[1] += 1\n",
    "\n",
    "\n",
    "            if self.players[player_id].actions == []:\n",
    "                return self.desk, 0, True, True\n",
    "            else:\n",
    "                return self.desk, 0, True, False\n",
    "\n",
    "        return self.desk, 0, False, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f12c38e",
   "metadata": {
    "_cell_guid": "2fcaa918-1252-4c2a-a6a6-9a3e888a3c0e",
    "_uuid": "4d4eb8c4-6d56-4731-9d16-76bcfbccace6",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-07-11T06:31:25.048067Z",
     "iopub.status.busy": "2024-07-11T06:31:25.047753Z",
     "iopub.status.idle": "2024-07-11T06:31:25.058879Z",
     "shell.execute_reply": "2024-07-11T06:31:25.058040Z"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1720234044731,
     "user": {
      "displayName": "J. V. G. Ransika",
      "userId": "13058150827256079313"
     },
     "user_tz": -330
    },
    "id": "UTFbQqVh-1OJ",
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.020292,
     "end_time": "2024-07-11T06:31:25.061239",
     "exception": false,
     "start_time": "2024-07-11T06:31:25.040947",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Player:\n",
    "    def __init__(self, env, policy_net, value_net, team, id):\n",
    "        self.policy_net = policy_net\n",
    "        self.value_net = value_net\n",
    "        self.env = env\n",
    "        self.actions = []\n",
    "        self.pre_rewards = []\n",
    "        self.policy_hidden = self.policy_net.init_hidden(1)\n",
    "        self.value_hidden = self.value_net.init_hidden(1)\n",
    "        self.team = team\n",
    "        self.id = id\n",
    "\n",
    "\n",
    "    def reset_hidden(self):\n",
    "        self.policy_hidden = self.policy_net.init_hidden(1)\n",
    "        self.value_hidden = self.value_net.init_hidden(1)\n",
    "\n",
    "\n",
    "    def play(self):\n",
    "        state = torch.tensor(input_arr(self.env.trump, self.env.hand, self.actions, [c for i, c in enumerate(self.env.desk) if i%2 == self.team], [c for i, c in enumerate(self.env.desk) if i%2 != self.team]), dtype=torch.float32).unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "        # state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).unsqueeze(0)\n",
    "        available_cards_mask = torch.tensor(sym_to_cat(self.actions, CARDS))\n",
    "        available_cards_mask = available_cards_mask.to(torch.bool)\n",
    "\n",
    "        action_probs, self.policy_hidden = self.policy_net(state, self.policy_hidden, available_cards_mask)\n",
    "\n",
    "        try:\n",
    "            action = torch.argmax(action_probs, 1).item()\n",
    "        except RuntimeError:\n",
    "            print(f'action probs - {action_probs}')\n",
    "            print(f'state - {state}')\n",
    "            print(f'policy_hidden - {self.policy_hidden}')\n",
    "            raise RuntimeError\n",
    "\n",
    "        next_state, reward, r_done, done = self.env.step(CARDS[action], self.id)\n",
    "        \n",
    "        return state,action,reward, r_done, done, action_probs[0][action].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4cf0d34",
   "metadata": {
    "_cell_guid": "9b20ace7-a888-4657-aa9e-2cb6d1ac1d0b",
    "_uuid": "783a3daa-754e-470c-89e2-5c44c9652e5a",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-07-11T06:31:25.074350Z",
     "iopub.status.busy": "2024-07-11T06:31:25.074078Z",
     "iopub.status.idle": "2024-07-11T06:31:25.080015Z",
     "shell.execute_reply": "2024-07-11T06:31:25.079239Z"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1720234044731,
     "user": {
      "displayName": "J. V. G. Ransika",
      "userId": "13058150827256079313"
     },
     "user_tz": -330
    },
    "id": "pL_QxEzlJsrk",
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.014554,
     "end_time": "2024-07-11T06:31:25.081838",
     "exception": false,
     "start_time": "2024-07-11T06:31:25.067284",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.buffer = []\n",
    "\n",
    "    def push(self, state, action, reward, action_prob):\n",
    "        self.buffer.append((state, action, reward, action_prob))\n",
    "        if len(self.buffer) > self.capacity:\n",
    "            self.buffer.pop(0)\n",
    "        \n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.buffer, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.buffer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2f21604",
   "metadata": {
    "_cell_guid": "4b814f6d-f1e6-44da-af6f-eca61344941e",
    "_uuid": "2d1cb691-ae62-40ea-bc36-f6f718633a5c",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-07-11T06:31:25.094648Z",
     "iopub.status.busy": "2024-07-11T06:31:25.094405Z",
     "iopub.status.idle": "2024-07-11T06:31:25.097866Z",
     "shell.execute_reply": "2024-07-11T06:31:25.097004Z"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1720234045276,
     "user": {
      "displayName": "J. V. G. Ransika",
      "userId": "13058150827256079313"
     },
     "user_tz": -330
    },
    "id": "hjW4PCCI-1OK",
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.012205,
     "end_time": "2024-07-11T06:31:25.099728",
     "exception": false,
     "start_time": "2024-07-11T06:31:25.087523",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "# %load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8eaf75d",
   "metadata": {
    "_cell_guid": "778d6b4b-e43e-4901-8354-a1e3cea0dc77",
    "_uuid": "4a68b3de-7eec-4043-bcb3-89e6b313e007",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-07-11T06:31:25.112690Z",
     "iopub.status.busy": "2024-07-11T06:31:25.112116Z",
     "iopub.status.idle": "2024-07-11T06:31:39.141291Z",
     "shell.execute_reply": "2024-07-11T06:31:39.140494Z"
    },
    "executionInfo": {
     "elapsed": 4980,
     "status": "ok",
     "timestamp": 1720234051230,
     "user": {
      "displayName": "J. V. G. Ransika",
      "userId": "13058150827256079313"
     },
     "user_tz": -330
    },
    "id": "QkYLMPe-_UWZ",
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 14.038043,
     "end_time": "2024-07-11T06:31:39.143530",
     "exception": false,
     "start_time": "2024-07-11T06:31:25.105487",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-11 06:31:27.851841: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-11 06:31:27.851955: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-11 06:31:27.998059: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55aeda85",
   "metadata": {
    "_cell_guid": "7292c07d-915f-473d-903b-6432fe5f5681",
    "_uuid": "bf58f0fb-5d71-41dc-ba14-c72ef93d353c",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-07-11T06:31:39.157698Z",
     "iopub.status.busy": "2024-07-11T06:31:39.157136Z",
     "iopub.status.idle": "2024-07-11T09:38:07.558680Z",
     "shell.execute_reply": "2024-07-11T09:38:07.557864Z"
    },
    "id": "fkZQPMMk-1OK",
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 11188.411196,
     "end_time": "2024-07-11T09:38:07.561020",
     "exception": false,
     "start_time": "2024-07-11T06:31:39.149824",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating new policy model\n",
      "creating new value model\n",
      "Episode 250, Policy Loss: , Value Loss: 466.36553955078125\n",
      "Episode 260, Policy Loss: , Value Loss: 526.7574462890625\n",
      "Episode 270, Policy Loss: , Value Loss: 589.7896118164062\n",
      "Episode 280, Policy Loss: , Value Loss: 664.8306274414062\n",
      "Episode 290, Policy Loss: , Value Loss: 748.8280639648438\n",
      "Episode 300, Policy Loss: , Value Loss: 833.1404418945312\n",
      "Episode 310, Policy Loss: , Value Loss: 915.961669921875\n",
      "Episode 320, Policy Loss: , Value Loss: 1006.14404296875\n",
      "Episode 330, Policy Loss: , Value Loss: 1100.9150390625\n",
      "Episode 340, Policy Loss: , Value Loss: 1194.9593505859375\n",
      "Episode 350, Policy Loss: , Value Loss: 1295.819580078125\n",
      "Episode 360, Policy Loss: , Value Loss: 1407.4720458984375\n",
      "Episode 370, Policy Loss: , Value Loss: 1517.032958984375\n",
      "Episode 380, Policy Loss: , Value Loss: 1630.9869384765625\n",
      "Episode 390, Policy Loss: , Value Loss: 1757.8873291015625\n",
      "Episode 400, Policy Loss: , Value Loss: 1887.6246337890625\n",
      "Episode 410, Policy Loss: , Value Loss: 2030.947021484375\n",
      "Episode 420, Policy Loss: , Value Loss: 2183.49609375\n",
      "Episode 430, Policy Loss: , Value Loss: 2335.64599609375\n",
      "Episode 440, Policy Loss: , Value Loss: 2515.41064453125\n",
      "Episode 450, Policy Loss: , Value Loss: 2709.671630859375\n",
      "Episode 460, Policy Loss: , Value Loss: 2919.9541015625\n",
      "Episode 470, Policy Loss: , Value Loss: 3153.1455078125\n",
      "Episode 480, Policy Loss: , Value Loss: 3388.8330078125\n",
      "Episode 490, Policy Loss: , Value Loss: 3640.652099609375\n",
      "Episode 500, Policy Loss: , Value Loss: 3893.15771484375\n",
      "Episode 510, Policy Loss: , Value Loss: 4148.87890625\n",
      "Episode 520, Policy Loss: , Value Loss: 4417.6142578125\n",
      "Episode 530, Policy Loss: , Value Loss: 4690.01513671875\n",
      "Episode 540, Policy Loss: , Value Loss: 4982.875\n",
      "Episode 550, Policy Loss: , Value Loss: 5282.42919921875\n",
      "Episode 560, Policy Loss: , Value Loss: 5601.845703125\n",
      "Episode 570, Policy Loss: , Value Loss: 5933.814453125\n",
      "Episode 580, Policy Loss: , Value Loss: 6294.09423828125\n",
      "Episode 590, Policy Loss: , Value Loss: 6677.02001953125\n",
      "Episode 600, Policy Loss: , Value Loss: 7075.13720703125\n",
      "Episode 610, Policy Loss: , Value Loss: 7467.46826171875\n",
      "Episode 620, Policy Loss: , Value Loss: 7892.31884765625\n",
      "Episode 630, Policy Loss: , Value Loss: 8300.623046875\n",
      "Episode 640, Policy Loss: , Value Loss: 8725.1025390625\n",
      "Episode 650, Policy Loss: , Value Loss: 9161.26953125\n",
      "Episode 660, Policy Loss: , Value Loss: 9611.19140625\n",
      "Episode 670, Policy Loss: , Value Loss: 10049.7587890625\n",
      "Episode 680, Policy Loss: , Value Loss: 10494.75390625\n",
      "Episode 690, Policy Loss: , Value Loss: 10916.98828125\n",
      "Episode 700, Policy Loss: , Value Loss: 11369.1962890625\n",
      "Episode 710, Policy Loss: , Value Loss: 11842.01953125\n",
      "Episode 720, Policy Loss: , Value Loss: 12319.419921875\n",
      "Episode 730, Policy Loss: , Value Loss: 12797.1767578125\n",
      "Episode 740, Policy Loss: , Value Loss: 13283.4287109375\n",
      "Episode 750, Policy Loss: , Value Loss: 13784.9111328125\n",
      "Episode 760, Policy Loss: , Value Loss: 14288.814453125\n",
      "Episode 770, Policy Loss: , Value Loss: 14811.0927734375\n",
      "Episode 780, Policy Loss: , Value Loss: 15303.8837890625\n",
      "Episode 790, Policy Loss: , Value Loss: 15819.6826171875\n",
      "Episode 800, Policy Loss: , Value Loss: 16333.22265625\n",
      "Episode 810, Policy Loss: , Value Loss: 16848.111328125\n",
      "Episode 820, Policy Loss: , Value Loss: 17367.388671875\n",
      "Episode 830, Policy Loss: , Value Loss: 17882.29296875\n",
      "Episode 840, Policy Loss: , Value Loss: 18403.67578125\n",
      "Episode 850, Policy Loss: , Value Loss: 18923.359375\n",
      "Episode 860, Policy Loss: , Value Loss: 19451.8125\n",
      "Episode 870, Policy Loss: , Value Loss: 19977.998046875\n",
      "Episode 880, Policy Loss: , Value Loss: 20521.001953125\n",
      "Episode 890, Policy Loss: , Value Loss: 21071.05078125\n",
      "Episode 900, Policy Loss: , Value Loss: 21588.35546875\n",
      "Episode 910, Policy Loss: , Value Loss: 22117.15234375\n",
      "Episode 920, Policy Loss: , Value Loss: 22650.234375\n",
      "Episode 930, Policy Loss: , Value Loss: 23202.03515625\n",
      "Episode 940, Policy Loss: , Value Loss: 23773.080078125\n",
      "Episode 950, Policy Loss: , Value Loss: 24343.1796875\n",
      "Episode 960, Policy Loss: , Value Loss: 24924.37109375\n",
      "Episode 970, Policy Loss: , Value Loss: 25504.01171875\n",
      "Episode 980, Policy Loss: , Value Loss: 26076.79296875\n",
      "Episode 990, Policy Loss: , Value Loss: 26674.921875\n",
      "Episode 1000, Policy Loss: , Value Loss: 27254.453125\n",
      "Episode 1010, Policy Loss: , Value Loss: 27855.69921875\n",
      "Episode 1020, Policy Loss: , Value Loss: 28419.505859375\n",
      "Episode 1030, Policy Loss: , Value Loss: 29005.669921875\n",
      "Episode 1040, Policy Loss: , Value Loss: 29607.638671875\n",
      "Episode 1050, Policy Loss: , Value Loss: 30225.515625\n",
      "Episode 1060, Policy Loss: , Value Loss: 30888.47265625\n",
      "Episode 1070, Policy Loss: , Value Loss: 31534.994140625\n",
      "Episode 1080, Policy Loss: , Value Loss: 32175.34375\n",
      "Episode 1090, Policy Loss: , Value Loss: 32811.70703125\n",
      "Episode 1100, Policy Loss: , Value Loss: 33422.390625\n",
      "Episode 1110, Policy Loss: , Value Loss: 34081.70703125\n",
      "Episode 1120, Policy Loss: , Value Loss: 34792.9140625\n",
      "Episode 1130, Policy Loss: , Value Loss: 35490.67578125\n",
      "Episode 1140, Policy Loss: , Value Loss: 36233.77734375\n",
      "Episode 1150, Policy Loss: , Value Loss: 36967.91796875\n",
      "Episode 1160, Policy Loss: , Value Loss: 37765.37890625\n",
      "Episode 1170, Policy Loss: , Value Loss: 38554.2421875\n",
      "Episode 1180, Policy Loss: , Value Loss: 39362.68359375\n",
      "Episode 1190, Policy Loss: , Value Loss: 40163.60546875\n",
      "Episode 1200, Policy Loss: , Value Loss: 40947.6328125\n",
      "Episode 1210, Policy Loss: , Value Loss: 41698.9296875\n",
      "Episode 1220, Policy Loss: , Value Loss: 42562.8671875\n",
      "Episode 1230, Policy Loss: , Value Loss: 43420.921875\n",
      "Episode 1240, Policy Loss: , Value Loss: 44247.7421875\n",
      "Episode 1250, Policy Loss: , Value Loss: 45122.65625\n",
      "Episode 1260, Policy Loss: , Value Loss: 45979.6171875\n",
      "Episode 1270, Policy Loss: , Value Loss: 46872.82421875\n",
      "Episode 1280, Policy Loss: , Value Loss: 47751.90234375\n",
      "Episode 1290, Policy Loss: , Value Loss: 48641.0\n",
      "Episode 1300, Policy Loss: , Value Loss: 49503.5234375\n",
      "Episode 1310, Policy Loss: , Value Loss: 50377.171875\n",
      "Episode 1320, Policy Loss: , Value Loss: 51245.5078125\n",
      "Episode 1330, Policy Loss: , Value Loss: 52183.4921875\n",
      "Episode 1340, Policy Loss: , Value Loss: 53190.734375\n",
      "Episode 1350, Policy Loss: , Value Loss: 54236.30859375\n",
      "Episode 1360, Policy Loss: , Value Loss: 55280.6796875\n",
      "Episode 1370, Policy Loss: , Value Loss: 56293.59765625\n",
      "Episode 1380, Policy Loss: , Value Loss: 57397.61328125\n",
      "Episode 1390, Policy Loss: , Value Loss: 58500.63671875\n",
      "Episode 1400, Policy Loss: , Value Loss: 59643.7578125\n",
      "Episode 1410, Policy Loss: , Value Loss: 60779.671875\n",
      "Episode 1420, Policy Loss: , Value Loss: 61950.48828125\n",
      "Episode 1430, Policy Loss: , Value Loss: 63113.78515625\n",
      "Episode 1440, Policy Loss: , Value Loss: 64248.08203125\n",
      "Episode 1450, Policy Loss: , Value Loss: 65403.08203125\n",
      "Episode 1460, Policy Loss: , Value Loss: 66560.578125\n",
      "Episode 1470, Policy Loss: , Value Loss: 67680.2734375\n",
      "Episode 1480, Policy Loss: , Value Loss: 68811.640625\n",
      "Episode 1490, Policy Loss: , Value Loss: 69961.203125\n",
      "Episode 1500, Policy Loss: , Value Loss: 71153.3828125\n",
      "Episode 1510, Policy Loss: , Value Loss: 72356.078125\n",
      "Episode 1520, Policy Loss: , Value Loss: 73620.546875\n",
      "Episode 1530, Policy Loss: , Value Loss: 74884.4375\n",
      "Episode 1540, Policy Loss: , Value Loss: 76172.6796875\n",
      "Episode 1550, Policy Loss: , Value Loss: 77496.4375\n",
      "Episode 1560, Policy Loss: , Value Loss: 78780.0078125\n",
      "Episode 1570, Policy Loss: , Value Loss: 80064.8125\n",
      "Episode 1580, Policy Loss: , Value Loss: 81278.2421875\n",
      "Episode 1590, Policy Loss: , Value Loss: 82480.625\n",
      "Episode 1600, Policy Loss: , Value Loss: 83646.921875\n",
      "Episode 1610, Policy Loss: , Value Loss: 84793.8671875\n",
      "Episode 1620, Policy Loss: , Value Loss: 85970.8125\n",
      "Episode 1630, Policy Loss: , Value Loss: 87097.0546875\n",
      "Episode 1640, Policy Loss: , Value Loss: 88167.9921875\n",
      "Episode 1650, Policy Loss: , Value Loss: 89241.3203125\n",
      "Episode 1660, Policy Loss: , Value Loss: 90270.828125\n",
      "Episode 1670, Policy Loss: , Value Loss: 91369.75\n",
      "Episode 1680, Policy Loss: , Value Loss: 92444.96875\n",
      "Episode 1690, Policy Loss: , Value Loss: 93578.390625\n",
      "Episode 1700, Policy Loss: , Value Loss: 94664.515625\n",
      "Episode 1710, Policy Loss: , Value Loss: 95821.1796875\n",
      "Episode 1720, Policy Loss: , Value Loss: 96923.2734375\n",
      "Episode 1730, Policy Loss: , Value Loss: 97968.328125\n",
      "Episode 1740, Policy Loss: , Value Loss: 99099.515625\n",
      "Episode 1750, Policy Loss: , Value Loss: 100259.625\n",
      "Episode 1760, Policy Loss: , Value Loss: 101409.453125\n",
      "Episode 1770, Policy Loss: , Value Loss: 102533.875\n",
      "Episode 1780, Policy Loss: , Value Loss: 103632.765625\n",
      "Episode 1790, Policy Loss: , Value Loss: 104748.5078125\n",
      "Episode 1800, Policy Loss: , Value Loss: 105863.6875\n",
      "Episode 1810, Policy Loss: , Value Loss: 106996.25\n",
      "Episode 1820, Policy Loss: , Value Loss: 108121.2421875\n",
      "Episode 1830, Policy Loss: , Value Loss: 109258.953125\n",
      "Episode 1840, Policy Loss: , Value Loss: 110404.53125\n",
      "Episode 1850, Policy Loss: , Value Loss: 111586.0703125\n",
      "Episode 1860, Policy Loss: , Value Loss: 112772.2109375\n",
      "Episode 1870, Policy Loss: , Value Loss: 113997.5\n",
      "Episode 1880, Policy Loss: , Value Loss: 115232.7421875\n",
      "Episode 1890, Policy Loss: , Value Loss: 116500.578125\n",
      "Episode 1900, Policy Loss: , Value Loss: 117714.3828125\n",
      "Episode 1910, Policy Loss: , Value Loss: 118923.921875\n",
      "Episode 1920, Policy Loss: , Value Loss: 120150.046875\n",
      "Episode 1930, Policy Loss: , Value Loss: 121382.1796875\n",
      "Episode 1940, Policy Loss: , Value Loss: 122621.515625\n",
      "Episode 1950, Policy Loss: , Value Loss: 123903.453125\n",
      "Episode 1960, Policy Loss: , Value Loss: 125178.171875\n",
      "Episode 1970, Policy Loss: , Value Loss: 126554.28125\n",
      "Episode 1980, Policy Loss: , Value Loss: 127952.0234375\n",
      "Episode 1990, Policy Loss: , Value Loss: 129286.6796875\n",
      "Episode 2000, Policy Loss: , Value Loss: 130565.8671875\n",
      "Episode 2010, Policy Loss: , Value Loss: 131978.21875\n",
      "Episode 2020, Policy Loss: , Value Loss: 133423.015625\n",
      "Episode 2030, Policy Loss: , Value Loss: 134902.171875\n",
      "Episode 2040, Policy Loss: , Value Loss: 136432.6875\n",
      "Episode 2050, Policy Loss: , Value Loss: 137956.84375\n",
      "Episode 2060, Policy Loss: , Value Loss: 139531.5625\n",
      "Episode 2070, Policy Loss: , Value Loss: 141207.34375\n",
      "Episode 2080, Policy Loss: , Value Loss: 142951.203125\n",
      "Episode 2090, Policy Loss: , Value Loss: 144725.65625\n",
      "Episode 2100, Policy Loss: , Value Loss: 146567.0\n",
      "Episode 2110, Policy Loss: , Value Loss: 148280.75\n",
      "Episode 2120, Policy Loss: , Value Loss: 150057.265625\n",
      "Episode 2130, Policy Loss: , Value Loss: 151824.90625\n",
      "Episode 2140, Policy Loss: , Value Loss: 153620.5625\n",
      "Episode 2150, Policy Loss: , Value Loss: 155426.921875\n",
      "Episode 2160, Policy Loss: , Value Loss: 157320.296875\n",
      "Episode 2170, Policy Loss: , Value Loss: 159194.265625\n",
      "Episode 2180, Policy Loss: , Value Loss: 161063.546875\n",
      "Episode 2190, Policy Loss: , Value Loss: 162923.21875\n",
      "Episode 2200, Policy Loss: , Value Loss: 164797.578125\n",
      "Episode 2210, Policy Loss: , Value Loss: 166767.859375\n",
      "Episode 2220, Policy Loss: , Value Loss: 168652.828125\n",
      "Episode 2230, Policy Loss: , Value Loss: 170666.578125\n",
      "Episode 2240, Policy Loss: , Value Loss: 172771.96875\n",
      "Episode 2250, Policy Loss: , Value Loss: 174784.375\n",
      "Episode 2260, Policy Loss: , Value Loss: 176726.59375\n",
      "Episode 2270, Policy Loss: , Value Loss: 178636.203125\n",
      "Episode 2280, Policy Loss: , Value Loss: 180668.5\n",
      "Episode 2290, Policy Loss: , Value Loss: 182744.0625\n",
      "Episode 2300, Policy Loss: , Value Loss: 184766.09375\n",
      "Episode 2310, Policy Loss: , Value Loss: 186856.5\n",
      "Episode 2320, Policy Loss: , Value Loss: 188917.109375\n",
      "Episode 2330, Policy Loss: , Value Loss: 190975.96875\n",
      "Episode 2340, Policy Loss: , Value Loss: 193001.640625\n",
      "Episode 2350, Policy Loss: , Value Loss: 195139.046875\n",
      "Episode 2360, Policy Loss: , Value Loss: 197201.109375\n",
      "Episode 2370, Policy Loss: , Value Loss: 199304.328125\n",
      "Episode 2380, Policy Loss: , Value Loss: 201355.21875\n",
      "Episode 2390, Policy Loss: , Value Loss: 203448.25\n",
      "Episode 2400, Policy Loss: , Value Loss: 205462.15625\n",
      "Episode 2410, Policy Loss: , Value Loss: 207513.0625\n",
      "Episode 2420, Policy Loss: , Value Loss: 209554.546875\n",
      "Episode 2430, Policy Loss: , Value Loss: 211760.6875\n",
      "Episode 2440, Policy Loss: , Value Loss: 214102.828125\n",
      "Episode 2450, Policy Loss: , Value Loss: 216370.75\n",
      "Episode 2460, Policy Loss: , Value Loss: 218575.90625\n",
      "Episode 2470, Policy Loss: , Value Loss: 220885.84375\n",
      "Episode 2480, Policy Loss: , Value Loss: 223183.515625\n",
      "Episode 2490, Policy Loss: , Value Loss: 225425.15625\n",
      "Episode 2500, Policy Loss: , Value Loss: 227648.125\n",
      "Episode 2510, Policy Loss: , Value Loss: 229903.125\n",
      "Episode 2520, Policy Loss: , Value Loss: 232134.71875\n",
      "Episode 2530, Policy Loss: , Value Loss: 234220.171875\n",
      "Episode 2540, Policy Loss: , Value Loss: 236317.0\n",
      "Episode 2550, Policy Loss: , Value Loss: 238421.96875\n",
      "Episode 2560, Policy Loss: , Value Loss: 240523.84375\n",
      "Episode 2570, Policy Loss: , Value Loss: 242584.015625\n",
      "Episode 2580, Policy Loss: , Value Loss: 244642.640625\n",
      "Episode 2590, Policy Loss: , Value Loss: 246735.109375\n",
      "Episode 2600, Policy Loss: , Value Loss: 248795.390625\n",
      "Episode 2610, Policy Loss: , Value Loss: 250901.296875\n",
      "Episode 2620, Policy Loss: , Value Loss: 252946.09375\n",
      "Episode 2630, Policy Loss: , Value Loss: 255069.59375\n",
      "Episode 2640, Policy Loss: , Value Loss: 257132.671875\n",
      "Episode 2650, Policy Loss: , Value Loss: 259205.796875\n",
      "Episode 2660, Policy Loss: , Value Loss: 261275.1875\n",
      "Episode 2670, Policy Loss: , Value Loss: 263317.15625\n",
      "Episode 2680, Policy Loss: , Value Loss: 265287.5\n",
      "Episode 2690, Policy Loss: , Value Loss: 267239.78125\n",
      "Episode 2700, Policy Loss: , Value Loss: 269265.5625\n",
      "Episode 2710, Policy Loss: , Value Loss: 271258.3125\n",
      "Episode 2720, Policy Loss: , Value Loss: 273169.84375\n",
      "Episode 2730, Policy Loss: , Value Loss: 275030.59375\n",
      "Episode 2740, Policy Loss: , Value Loss: 276874.6875\n",
      "Episode 2750, Policy Loss: , Value Loss: 278798.84375\n",
      "Episode 2760, Policy Loss: , Value Loss: 280694.9375\n",
      "Episode 2770, Policy Loss: , Value Loss: 282681.71875\n",
      "Episode 2780, Policy Loss: , Value Loss: 284683.09375\n",
      "Episode 2790, Policy Loss: , Value Loss: 286689.5625\n",
      "Episode 2800, Policy Loss: , Value Loss: 288791.1875\n",
      "Episode 2810, Policy Loss: , Value Loss: 290936.59375\n",
      "Episode 2820, Policy Loss: , Value Loss: 293022.59375\n",
      "Episode 2830, Policy Loss: , Value Loss: 295028.40625\n",
      "Episode 2840, Policy Loss: , Value Loss: 297070.75\n",
      "Episode 2850, Policy Loss: , Value Loss: 299172.4375\n",
      "Episode 2860, Policy Loss: , Value Loss: 301330.0625\n",
      "Episode 2870, Policy Loss: , Value Loss: 303608.34375\n",
      "Episode 2880, Policy Loss: , Value Loss: 305956.25\n",
      "Episode 2890, Policy Loss: , Value Loss: 308477.1875\n",
      "Episode 2900, Policy Loss: , Value Loss: 311141.46875\n",
      "Episode 2910, Policy Loss: , Value Loss: 313885.59375\n",
      "Episode 2920, Policy Loss: , Value Loss: 316602.78125\n",
      "Episode 2930, Policy Loss: , Value Loss: 319258.6875\n",
      "Episode 2940, Policy Loss: , Value Loss: 321864.0625\n",
      "Episode 2950, Policy Loss: , Value Loss: 324466.9375\n",
      "Episode 2960, Policy Loss: , Value Loss: 327255.625\n",
      "Episode 2970, Policy Loss: , Value Loss: 330021.28125\n",
      "Episode 2980, Policy Loss: , Value Loss: 332904.03125\n",
      "Episode 2990, Policy Loss: , Value Loss: 335827.90625\n",
      "Episode 3000, Policy Loss: , Value Loss: 338747.0625\n",
      "Episode 3010, Policy Loss: , Value Loss: 341701.03125\n",
      "Episode 3020, Policy Loss: , Value Loss: 344783.1875\n",
      "Episode 3030, Policy Loss: , Value Loss: 347863.25\n",
      "Episode 3040, Policy Loss: , Value Loss: 351071.53125\n",
      "Episode 3050, Policy Loss: , Value Loss: 354245.53125\n",
      "Episode 3060, Policy Loss: , Value Loss: 357363.71875\n",
      "Episode 3070, Policy Loss: , Value Loss: 360473.25\n",
      "Episode 3080, Policy Loss: , Value Loss: 363719.59375\n",
      "Episode 3090, Policy Loss: , Value Loss: 366900.28125\n",
      "Episode 3100, Policy Loss: , Value Loss: 369936.96875\n",
      "Episode 3110, Policy Loss: , Value Loss: 372951.78125\n",
      "Episode 3120, Policy Loss: , Value Loss: 375817.34375\n",
      "Episode 3130, Policy Loss: , Value Loss: 378697.78125\n",
      "Episode 3140, Policy Loss: , Value Loss: 381516.71875\n",
      "Episode 3150, Policy Loss: , Value Loss: 384318.40625\n",
      "Episode 3160, Policy Loss: , Value Loss: 387162.0\n",
      "Episode 3170, Policy Loss: , Value Loss: 389980.1875\n",
      "Episode 3180, Policy Loss: , Value Loss: 392869.25\n",
      "Episode 3190, Policy Loss: , Value Loss: 395755.03125\n",
      "Episode 3200, Policy Loss: , Value Loss: 398569.1875\n",
      "Episode 3210, Policy Loss: , Value Loss: 401388.03125\n",
      "Episode 3220, Policy Loss: , Value Loss: 404166.59375\n",
      "Episode 3230, Policy Loss: , Value Loss: 407012.46875\n",
      "Episode 3240, Policy Loss: , Value Loss: 409808.96875\n",
      "Episode 3250, Policy Loss: , Value Loss: 412612.34375\n",
      "Episode 3260, Policy Loss: , Value Loss: 415342.59375\n",
      "Episode 3270, Policy Loss: , Value Loss: 417938.96875\n",
      "Episode 3280, Policy Loss: , Value Loss: 420529.46875\n",
      "Episode 3290, Policy Loss: , Value Loss: 423007.1875\n",
      "Episode 3300, Policy Loss: , Value Loss: 425591.90625\n",
      "Episode 3310, Policy Loss: , Value Loss: 428195.0625\n",
      "Episode 3320, Policy Loss: , Value Loss: 430864.90625\n",
      "Episode 3330, Policy Loss: , Value Loss: 433418.4375\n",
      "Episode 3340, Policy Loss: , Value Loss: 436178.625\n",
      "Episode 3350, Policy Loss: , Value Loss: 438905.375\n",
      "Episode 3360, Policy Loss: , Value Loss: 441866.125\n",
      "Episode 3370, Policy Loss: , Value Loss: 444790.9375\n",
      "Episode 3380, Policy Loss: , Value Loss: 447579.28125\n",
      "Episode 3390, Policy Loss: , Value Loss: 450547.875\n",
      "Episode 3400, Policy Loss: , Value Loss: 453238.71875\n",
      "Episode 3410, Policy Loss: , Value Loss: 456219.25\n",
      "Episode 3420, Policy Loss: , Value Loss: 459114.59375\n",
      "Episode 3430, Policy Loss: , Value Loss: 462044.9375\n",
      "Episode 3440, Policy Loss: , Value Loss: 465027.0\n",
      "Episode 3450, Policy Loss: , Value Loss: 467940.46875\n",
      "Episode 3460, Policy Loss: , Value Loss: 470654.25\n",
      "Episode 3470, Policy Loss: , Value Loss: 473389.78125\n",
      "Episode 3480, Policy Loss: , Value Loss: 476073.28125\n",
      "Episode 3490, Policy Loss: , Value Loss: 478897.1875\n",
      "Episode 3500, Policy Loss: , Value Loss: 481878.8125\n",
      "Episode 3510, Policy Loss: , Value Loss: 484825.875\n",
      "Episode 3520, Policy Loss: , Value Loss: 487724.90625\n",
      "Episode 3530, Policy Loss: , Value Loss: 490600.09375\n",
      "Episode 3540, Policy Loss: , Value Loss: 493488.75\n",
      "Episode 3550, Policy Loss: , Value Loss: 496360.90625\n",
      "Episode 3560, Policy Loss: , Value Loss: 499198.0\n",
      "Episode 3570, Policy Loss: , Value Loss: 501971.0625\n",
      "Episode 3580, Policy Loss: , Value Loss: 504902.375\n",
      "Episode 3590, Policy Loss: , Value Loss: 507764.625\n",
      "Episode 3600, Policy Loss: , Value Loss: 510641.65625\n",
      "Episode 3610, Policy Loss: , Value Loss: 513593.03125\n",
      "Episode 3620, Policy Loss: , Value Loss: 516345.34375\n",
      "Episode 3630, Policy Loss: , Value Loss: 519358.25\n",
      "Episode 3640, Policy Loss: , Value Loss: 522274.53125\n",
      "Episode 3650, Policy Loss: , Value Loss: 525229.6875\n",
      "Episode 3660, Policy Loss: , Value Loss: 528097.5\n",
      "Episode 3670, Policy Loss: , Value Loss: 531138.0\n",
      "Episode 3680, Policy Loss: , Value Loss: 534104.125\n",
      "Episode 3690, Policy Loss: , Value Loss: 537195.0\n",
      "Episode 3700, Policy Loss: , Value Loss: 540110.4375\n",
      "Episode 3710, Policy Loss: , Value Loss: 543105.25\n",
      "Episode 3720, Policy Loss: , Value Loss: 546091.5625\n",
      "Episode 3730, Policy Loss: , Value Loss: 549253.1875\n",
      "Episode 3740, Policy Loss: , Value Loss: 552272.25\n",
      "Episode 3750, Policy Loss: , Value Loss: 555126.0\n",
      "Episode 3760, Policy Loss: , Value Loss: 558099.0\n",
      "Episode 3770, Policy Loss: , Value Loss: 561187.375\n",
      "Episode 3780, Policy Loss: , Value Loss: 564252.875\n",
      "Episode 3790, Policy Loss: , Value Loss: 567630.9375\n",
      "Episode 3800, Policy Loss: , Value Loss: 570869.25\n",
      "Episode 3810, Policy Loss: , Value Loss: 573991.9375\n",
      "Episode 3820, Policy Loss: , Value Loss: 577153.25\n",
      "Episode 3830, Policy Loss: , Value Loss: 580151.5\n",
      "Episode 3840, Policy Loss: , Value Loss: 583257.1875\n",
      "Episode 3850, Policy Loss: , Value Loss: 586419.625\n",
      "Episode 3860, Policy Loss: , Value Loss: 589736.1875\n",
      "Episode 3870, Policy Loss: , Value Loss: 593070.125\n",
      "Episode 3880, Policy Loss: , Value Loss: 596330.875\n",
      "Episode 3890, Policy Loss: , Value Loss: 599734.4375\n",
      "Episode 3900, Policy Loss: , Value Loss: 602890.625\n",
      "Episode 3910, Policy Loss: , Value Loss: 606095.625\n",
      "Episode 3920, Policy Loss: , Value Loss: 609390.4375\n",
      "Episode 3930, Policy Loss: , Value Loss: 612749.6875\n",
      "Episode 3940, Policy Loss: , Value Loss: 616268.125\n",
      "Episode 3950, Policy Loss: , Value Loss: 619668.875\n",
      "Episode 3960, Policy Loss: , Value Loss: 623138.0625\n",
      "Episode 3970, Policy Loss: , Value Loss: 626752.75\n",
      "Episode 3980, Policy Loss: , Value Loss: 630131.0625\n",
      "Episode 3990, Policy Loss: , Value Loss: 633470.9375\n",
      "Episode 4000, Policy Loss: , Value Loss: 636916.3125\n",
      "Episode 4010, Policy Loss: , Value Loss: 640172.875\n",
      "Episode 4020, Policy Loss: , Value Loss: 643609.4375\n",
      "Episode 4030, Policy Loss: , Value Loss: 646657.5\n",
      "Episode 4040, Policy Loss: , Value Loss: 649750.5\n",
      "Episode 4050, Policy Loss: , Value Loss: 652787.9375\n",
      "Episode 4060, Policy Loss: , Value Loss: 656084.375\n",
      "Episode 4070, Policy Loss: , Value Loss: 659553.75\n",
      "Episode 4080, Policy Loss: , Value Loss: 662919.4375\n",
      "Episode 4090, Policy Loss: , Value Loss: 666251.375\n",
      "Episode 4100, Policy Loss: , Value Loss: 669487.5625\n",
      "Episode 4110, Policy Loss: , Value Loss: 672665.3125\n",
      "Episode 4120, Policy Loss: , Value Loss: 675871.125\n",
      "Episode 4130, Policy Loss: , Value Loss: 679271.5\n",
      "Episode 4140, Policy Loss: , Value Loss: 682534.875\n",
      "Episode 4150, Policy Loss: , Value Loss: 685777.6875\n",
      "Episode 4160, Policy Loss: , Value Loss: 689143.5625\n",
      "Episode 4170, Policy Loss: , Value Loss: 692486.5\n",
      "Episode 4180, Policy Loss: , Value Loss: 695811.3125\n",
      "Episode 4190, Policy Loss: , Value Loss: 699241.1875\n",
      "Episode 4200, Policy Loss: , Value Loss: 702929.125\n",
      "Episode 4210, Policy Loss: , Value Loss: 706702.625\n",
      "Episode 4220, Policy Loss: , Value Loss: 710463.9375\n",
      "Episode 4230, Policy Loss: , Value Loss: 714293.0625\n",
      "Episode 4240, Policy Loss: , Value Loss: 718536.25\n",
      "Episode 4250, Policy Loss: , Value Loss: 722628.5625\n",
      "Episode 4260, Policy Loss: , Value Loss: 726769.75\n",
      "Episode 4270, Policy Loss: , Value Loss: 731198.125\n",
      "Episode 4280, Policy Loss: , Value Loss: 735598.75\n",
      "Episode 4290, Policy Loss: , Value Loss: 740151.9375\n",
      "Episode 4300, Policy Loss: , Value Loss: 744782.9375\n",
      "Episode 4310, Policy Loss: , Value Loss: 748964.8125\n",
      "Episode 4320, Policy Loss: , Value Loss: 753354.0625\n",
      "Episode 4330, Policy Loss: , Value Loss: 757693.0\n",
      "Episode 4340, Policy Loss: , Value Loss: 762228.0\n",
      "Episode 4350, Policy Loss: , Value Loss: 766626.9375\n",
      "Episode 4360, Policy Loss: , Value Loss: 771222.125\n",
      "Episode 4370, Policy Loss: , Value Loss: 775614.9375\n",
      "Episode 4380, Policy Loss: , Value Loss: 780093.8125\n",
      "Episode 4390, Policy Loss: , Value Loss: 784685.5\n",
      "Episode 4400, Policy Loss: , Value Loss: 788896.1875\n",
      "Episode 4410, Policy Loss: , Value Loss: 793359.4375\n",
      "Episode 4420, Policy Loss: , Value Loss: 797771.625\n",
      "Episode 4430, Policy Loss: , Value Loss: 802120.25\n",
      "Episode 4440, Policy Loss: , Value Loss: 806285.5625\n",
      "Episode 4450, Policy Loss: , Value Loss: 810368.875\n",
      "Episode 4460, Policy Loss: , Value Loss: 814493.125\n",
      "Episode 4470, Policy Loss: , Value Loss: 818566.0\n",
      "Episode 4480, Policy Loss: , Value Loss: 822393.1875\n",
      "Episode 4490, Policy Loss: , Value Loss: 826128.1875\n",
      "Episode 4500, Policy Loss: , Value Loss: 829963.9375\n",
      "Episode 4510, Policy Loss: , Value Loss: 833677.9375\n",
      "Episode 4520, Policy Loss: , Value Loss: 837507.9375\n",
      "Episode 4530, Policy Loss: , Value Loss: 841135.375\n",
      "Episode 4540, Policy Loss: , Value Loss: 844820.5\n",
      "Episode 4550, Policy Loss: , Value Loss: 848407.4375\n",
      "Episode 4560, Policy Loss: , Value Loss: 852183.375\n",
      "Episode 4570, Policy Loss: , Value Loss: 855684.5\n",
      "Episode 4580, Policy Loss: , Value Loss: 859086.4375\n",
      "Episode 4590, Policy Loss: , Value Loss: 862512.8125\n",
      "Episode 4600, Policy Loss: , Value Loss: 865937.875\n",
      "Episode 4610, Policy Loss: , Value Loss: 869476.9375\n",
      "Episode 4620, Policy Loss: , Value Loss: 873084.9375\n",
      "Episode 4630, Policy Loss: , Value Loss: 876635.9375\n",
      "Episode 4640, Policy Loss: , Value Loss: 880009.0625\n",
      "Episode 4650, Policy Loss: , Value Loss: 883733.75\n",
      "Episode 4660, Policy Loss: , Value Loss: 887226.8125\n",
      "Episode 4670, Policy Loss: , Value Loss: 890596.3125\n",
      "Episode 4680, Policy Loss: , Value Loss: 893892.8125\n",
      "Episode 4690, Policy Loss: , Value Loss: 897155.5625\n",
      "Episode 4700, Policy Loss: , Value Loss: 900470.5\n",
      "Episode 4710, Policy Loss: , Value Loss: 903982.9375\n",
      "Episode 4720, Policy Loss: , Value Loss: 907636.125\n",
      "Episode 4730, Policy Loss: , Value Loss: 911197.4375\n",
      "Episode 4740, Policy Loss: , Value Loss: 914946.3125\n",
      "Episode 4750, Policy Loss: , Value Loss: 918552.6875\n",
      "Episode 4760, Policy Loss: , Value Loss: 922016.375\n",
      "Episode 4770, Policy Loss: , Value Loss: 925404.75\n",
      "Episode 4780, Policy Loss: , Value Loss: 928865.875\n",
      "Episode 4790, Policy Loss: , Value Loss: 932187.875\n",
      "Episode 4800, Policy Loss: , Value Loss: 935675.25\n",
      "Episode 4810, Policy Loss: , Value Loss: 939177.9375\n",
      "Episode 4820, Policy Loss: , Value Loss: 942688.75\n",
      "Episode 4830, Policy Loss: , Value Loss: 946409.6875\n",
      "Episode 4840, Policy Loss: , Value Loss: 950172.0\n",
      "Episode 4850, Policy Loss: , Value Loss: 953892.25\n",
      "Episode 4860, Policy Loss: , Value Loss: 957651.375\n",
      "Episode 4870, Policy Loss: , Value Loss: 961260.4375\n",
      "Episode 4880, Policy Loss: , Value Loss: 965114.5\n",
      "Episode 4890, Policy Loss: , Value Loss: 969069.25\n",
      "Episode 4900, Policy Loss: , Value Loss: 972874.9375\n",
      "Episode 4910, Policy Loss: , Value Loss: 976901.125\n",
      "Episode 4920, Policy Loss: , Value Loss: 980831.6875\n",
      "Episode 4930, Policy Loss: , Value Loss: 984814.5\n",
      "Episode 4940, Policy Loss: , Value Loss: 988978.5625\n",
      "Episode 4950, Policy Loss: , Value Loss: 992977.75\n",
      "Episode 4960, Policy Loss: , Value Loss: 997169.9375\n",
      "Episode 4970, Policy Loss: , Value Loss: 1001162.25\n",
      "Episode 4980, Policy Loss: , Value Loss: 1005140.3125\n",
      "Episode 4990, Policy Loss: , Value Loss: 1009264.0\n",
      "Episode 5000, Policy Loss: , Value Loss: 1013256.625\n",
      "Episode 5010, Policy Loss: , Value Loss: 1017524.625\n",
      "Episode 5020, Policy Loss: , Value Loss: 1021906.5625\n",
      "Episode 5030, Policy Loss: , Value Loss: 1026193.5625\n",
      "Episode 5040, Policy Loss: , Value Loss: 1030828.5\n",
      "Episode 5050, Policy Loss: , Value Loss: 1035611.5625\n",
      "Episode 5060, Policy Loss: , Value Loss: 1040498.9375\n",
      "Episode 5070, Policy Loss: , Value Loss: 1045534.375\n",
      "Episode 5080, Policy Loss: , Value Loss: 1050662.25\n",
      "Episode 5090, Policy Loss: , Value Loss: 1055757.0\n",
      "Episode 5100, Policy Loss: , Value Loss: 1060929.625\n",
      "Episode 5110, Policy Loss: , Value Loss: 1065960.0\n",
      "Episode 5120, Policy Loss: , Value Loss: 1071035.5\n",
      "Episode 5130, Policy Loss: , Value Loss: 1076070.375\n",
      "Episode 5140, Policy Loss: , Value Loss: 1080860.625\n",
      "Episode 5150, Policy Loss: , Value Loss: 1085901.75\n",
      "Episode 5160, Policy Loss: , Value Loss: 1090990.625\n",
      "Episode 5170, Policy Loss: , Value Loss: 1096201.125\n",
      "Episode 5180, Policy Loss: , Value Loss: 1101304.875\n",
      "Episode 5190, Policy Loss: , Value Loss: 1106458.375\n",
      "Episode 5200, Policy Loss: , Value Loss: 1111787.625\n",
      "Episode 5210, Policy Loss: , Value Loss: 1117025.0\n",
      "Episode 5220, Policy Loss: , Value Loss: 1122049.875\n",
      "Episode 5230, Policy Loss: , Value Loss: 1127139.5\n",
      "Episode 5240, Policy Loss: , Value Loss: 1132104.0\n",
      "Episode 5250, Policy Loss: , Value Loss: 1137361.125\n",
      "Episode 5260, Policy Loss: , Value Loss: 1142413.625\n",
      "Episode 5270, Policy Loss: , Value Loss: 1147390.5\n",
      "Episode 5280, Policy Loss: , Value Loss: 1152301.625\n",
      "Episode 5290, Policy Loss: , Value Loss: 1157112.625\n",
      "Episode 5300, Policy Loss: , Value Loss: 1161841.5\n",
      "Episode 5310, Policy Loss: , Value Loss: 1166468.25\n",
      "Episode 5320, Policy Loss: , Value Loss: 1170892.0\n",
      "Episode 5330, Policy Loss: , Value Loss: 1175166.5\n",
      "Episode 5340, Policy Loss: , Value Loss: 1179668.5\n",
      "Episode 5350, Policy Loss: , Value Loss: 1184085.5\n",
      "Episode 5360, Policy Loss: , Value Loss: 1188470.375\n",
      "Episode 5370, Policy Loss: , Value Loss: 1192995.25\n",
      "Episode 5380, Policy Loss: , Value Loss: 1197211.25\n",
      "Episode 5390, Policy Loss: , Value Loss: 1201560.5\n",
      "Episode 5400, Policy Loss: , Value Loss: 1205895.5\n",
      "Episode 5410, Policy Loss: , Value Loss: 1209911.125\n",
      "Episode 5420, Policy Loss: , Value Loss: 1213801.125\n",
      "Episode 5430, Policy Loss: , Value Loss: 1217606.75\n",
      "Episode 5440, Policy Loss: , Value Loss: 1221167.125\n",
      "Episode 5450, Policy Loss: , Value Loss: 1224474.25\n",
      "Episode 5460, Policy Loss: , Value Loss: 1227803.375\n",
      "Episode 5470, Policy Loss: , Value Loss: 1231188.375\n",
      "Episode 5480, Policy Loss: , Value Loss: 1234771.25\n",
      "Episode 5490, Policy Loss: , Value Loss: 1238429.375\n",
      "Episode 5500, Policy Loss: , Value Loss: 1242366.0\n",
      "Episode 5510, Policy Loss: , Value Loss: 1246197.125\n",
      "Episode 5520, Policy Loss: , Value Loss: 1250319.625\n",
      "Episode 5530, Policy Loss: , Value Loss: 1254300.375\n",
      "Episode 5540, Policy Loss: , Value Loss: 1258332.75\n",
      "Episode 5550, Policy Loss: , Value Loss: 1262586.25\n",
      "Episode 5560, Policy Loss: , Value Loss: 1266896.0\n",
      "Episode 5570, Policy Loss: , Value Loss: 1271390.375\n",
      "Episode 5580, Policy Loss: , Value Loss: 1275648.0\n",
      "Episode 5590, Policy Loss: , Value Loss: 1279972.875\n",
      "Episode 5600, Policy Loss: , Value Loss: 1284284.375\n",
      "Episode 5610, Policy Loss: , Value Loss: 1288376.0\n",
      "Episode 5620, Policy Loss: , Value Loss: 1292833.5\n",
      "Episode 5630, Policy Loss: , Value Loss: 1297300.875\n",
      "Episode 5640, Policy Loss: , Value Loss: 1301629.0\n",
      "Episode 5650, Policy Loss: , Value Loss: 1306126.875\n",
      "Episode 5660, Policy Loss: , Value Loss: 1310652.375\n",
      "Episode 5670, Policy Loss: , Value Loss: 1315469.75\n",
      "Episode 5680, Policy Loss: , Value Loss: 1320472.0\n",
      "Episode 5690, Policy Loss: , Value Loss: 1325679.25\n",
      "Episode 5700, Policy Loss: , Value Loss: 1331021.25\n",
      "Episode 5710, Policy Loss: , Value Loss: 1336567.5\n",
      "Episode 5720, Policy Loss: , Value Loss: 1341932.5\n",
      "Episode 5730, Policy Loss: , Value Loss: 1347277.25\n",
      "Episode 5740, Policy Loss: , Value Loss: 1352653.0\n",
      "Episode 5750, Policy Loss: , Value Loss: 1357589.625\n",
      "Episode 5760, Policy Loss: , Value Loss: 1362772.25\n",
      "Episode 5770, Policy Loss: , Value Loss: 1367816.625\n",
      "Episode 5780, Policy Loss: , Value Loss: 1373086.375\n",
      "Episode 5790, Policy Loss: , Value Loss: 1378423.5\n",
      "Episode 5800, Policy Loss: , Value Loss: 1383411.25\n",
      "Episode 5810, Policy Loss: , Value Loss: 1387938.25\n",
      "Episode 5820, Policy Loss: , Value Loss: 1392774.75\n",
      "Episode 5830, Policy Loss: , Value Loss: 1397319.5\n",
      "Episode 5840, Policy Loss: , Value Loss: 1402010.375\n",
      "Episode 5850, Policy Loss: , Value Loss: 1406772.125\n",
      "Episode 5860, Policy Loss: , Value Loss: 1411633.25\n",
      "Episode 5870, Policy Loss: , Value Loss: 1416316.625\n",
      "Episode 5880, Policy Loss: , Value Loss: 1421283.75\n",
      "Episode 5890, Policy Loss: , Value Loss: 1426131.0\n",
      "Episode 5900, Policy Loss: , Value Loss: 1431346.0\n",
      "Episode 5910, Policy Loss: , Value Loss: 1436397.5\n",
      "Episode 5920, Policy Loss: , Value Loss: 1441440.875\n",
      "Episode 5930, Policy Loss: , Value Loss: 1446524.125\n",
      "Episode 5940, Policy Loss: , Value Loss: 1451165.125\n",
      "Episode 5950, Policy Loss: , Value Loss: 1455912.375\n",
      "Episode 5960, Policy Loss: , Value Loss: 1460568.0\n",
      "Episode 5970, Policy Loss: , Value Loss: 1465279.625\n",
      "Episode 5980, Policy Loss: , Value Loss: 1469891.75\n",
      "Episode 5990, Policy Loss: , Value Loss: 1474471.75\n",
      "Episode 6000, Policy Loss: , Value Loss: 1478942.25\n",
      "Episode 6010, Policy Loss: , Value Loss: 1483345.125\n",
      "Episode 6020, Policy Loss: , Value Loss: 1487667.0\n",
      "Episode 6030, Policy Loss: , Value Loss: 1492084.25\n",
      "Episode 6040, Policy Loss: , Value Loss: 1496294.875\n",
      "Episode 6050, Policy Loss: , Value Loss: 1500823.25\n",
      "Episode 6060, Policy Loss: , Value Loss: 1505375.5\n",
      "Episode 6070, Policy Loss: , Value Loss: 1510009.5\n",
      "Episode 6080, Policy Loss: , Value Loss: 1514694.625\n",
      "Episode 6090, Policy Loss: , Value Loss: 1519102.75\n",
      "Episode 6100, Policy Loss: , Value Loss: 1523457.75\n",
      "Episode 6110, Policy Loss: , Value Loss: 1527813.125\n",
      "Episode 6120, Policy Loss: , Value Loss: 1531903.0\n",
      "Episode 6130, Policy Loss: , Value Loss: 1535955.875\n",
      "Episode 6140, Policy Loss: , Value Loss: 1540046.5\n",
      "Episode 6150, Policy Loss: , Value Loss: 1543950.75\n",
      "Episode 6160, Policy Loss: , Value Loss: 1547621.125\n",
      "Episode 6170, Policy Loss: , Value Loss: 1551626.75\n",
      "Episode 6180, Policy Loss: , Value Loss: 1555950.0\n",
      "Episode 6190, Policy Loss: , Value Loss: 1559890.125\n",
      "Episode 6200, Policy Loss: , Value Loss: 1564018.125\n",
      "Episode 6210, Policy Loss: , Value Loss: 1567948.375\n",
      "Episode 6220, Policy Loss: , Value Loss: 1571809.75\n",
      "Episode 6230, Policy Loss: , Value Loss: 1575977.75\n",
      "Episode 6240, Policy Loss: , Value Loss: 1580257.75\n",
      "Episode 6250, Policy Loss: , Value Loss: 1584553.375\n",
      "Episode 6260, Policy Loss: , Value Loss: 1589148.5\n",
      "Episode 6270, Policy Loss: , Value Loss: 1593831.125\n",
      "Episode 6280, Policy Loss: , Value Loss: 1598481.5\n",
      "Episode 6290, Policy Loss: , Value Loss: 1603145.875\n",
      "Episode 6300, Policy Loss: , Value Loss: 1607755.875\n",
      "Episode 6310, Policy Loss: , Value Loss: 1612332.875\n",
      "Episode 6320, Policy Loss: , Value Loss: 1617127.75\n",
      "Episode 6330, Policy Loss: , Value Loss: 1622060.375\n",
      "Episode 6340, Policy Loss: , Value Loss: 1626992.0\n",
      "Episode 6350, Policy Loss: , Value Loss: 1632150.125\n",
      "Episode 6360, Policy Loss: , Value Loss: 1637368.25\n",
      "Episode 6370, Policy Loss: , Value Loss: 1642916.5\n",
      "Episode 6380, Policy Loss: , Value Loss: 1648426.0\n",
      "Episode 6390, Policy Loss: , Value Loss: 1654184.375\n",
      "Episode 6400, Policy Loss: , Value Loss: 1659989.125\n",
      "Episode 6410, Policy Loss: , Value Loss: 1665954.75\n",
      "Episode 6420, Policy Loss: , Value Loss: 1671750.75\n",
      "Episode 6430, Policy Loss: , Value Loss: 1677370.75\n",
      "Episode 6440, Policy Loss: , Value Loss: 1683228.75\n",
      "Episode 6450, Policy Loss: , Value Loss: 1689219.25\n",
      "Episode 6460, Policy Loss: , Value Loss: 1695195.625\n",
      "Episode 6470, Policy Loss: , Value Loss: 1701300.625\n",
      "Episode 6480, Policy Loss: , Value Loss: 1707400.375\n",
      "Episode 6490, Policy Loss: , Value Loss: 1713515.375\n",
      "Episode 6500, Policy Loss: , Value Loss: 1719668.875\n",
      "Episode 6510, Policy Loss: , Value Loss: 1725541.25\n",
      "Episode 6520, Policy Loss: , Value Loss: 1731149.625\n",
      "Episode 6530, Policy Loss: , Value Loss: 1736905.25\n",
      "Episode 6540, Policy Loss: , Value Loss: 1742625.25\n",
      "Episode 6550, Policy Loss: , Value Loss: 1748298.5\n",
      "Episode 6560, Policy Loss: , Value Loss: 1754281.625\n",
      "Episode 6570, Policy Loss: , Value Loss: 1759790.125\n",
      "Episode 6580, Policy Loss: , Value Loss: 1765627.125\n",
      "Episode 6590, Policy Loss: , Value Loss: 1771376.25\n",
      "Episode 6600, Policy Loss: , Value Loss: 1777264.375\n",
      "Episode 6610, Policy Loss: , Value Loss: 1782902.25\n",
      "Episode 6620, Policy Loss: , Value Loss: 1788538.625\n",
      "Episode 6630, Policy Loss: , Value Loss: 1794338.875\n",
      "Episode 6640, Policy Loss: , Value Loss: 1800114.875\n",
      "Episode 6650, Policy Loss: , Value Loss: 1805503.625\n",
      "Episode 6660, Policy Loss: , Value Loss: 1811523.875\n",
      "Episode 6670, Policy Loss: , Value Loss: 1817310.125\n",
      "Episode 6680, Policy Loss: , Value Loss: 1822905.75\n",
      "Episode 6690, Policy Loss: , Value Loss: 1828983.375\n",
      "Episode 6700, Policy Loss: , Value Loss: 1835208.25\n",
      "Episode 6710, Policy Loss: , Value Loss: 1841458.125\n",
      "Episode 6720, Policy Loss: , Value Loss: 1847426.375\n",
      "Episode 6730, Policy Loss: , Value Loss: 1853576.25\n",
      "Episode 6740, Policy Loss: , Value Loss: 1859849.375\n",
      "Episode 6750, Policy Loss: , Value Loss: 1865632.625\n",
      "Episode 6760, Policy Loss: , Value Loss: 1871856.25\n",
      "Episode 6770, Policy Loss: , Value Loss: 1878087.75\n",
      "Episode 6780, Policy Loss: , Value Loss: 1884404.875\n",
      "Episode 6790, Policy Loss: , Value Loss: 1890367.875\n",
      "Episode 6800, Policy Loss: , Value Loss: 1896716.0\n",
      "Episode 6810, Policy Loss: , Value Loss: 1902545.875\n",
      "Episode 6820, Policy Loss: , Value Loss: 1908847.125\n",
      "Episode 6830, Policy Loss: , Value Loss: 1914938.0\n",
      "Episode 6840, Policy Loss: , Value Loss: 1921100.375\n",
      "Episode 6850, Policy Loss: , Value Loss: 1926780.625\n",
      "Episode 6860, Policy Loss: , Value Loss: 1932722.375\n",
      "Episode 6870, Policy Loss: , Value Loss: 1938569.875\n",
      "Episode 6880, Policy Loss: , Value Loss: 1944621.875\n",
      "Episode 6890, Policy Loss: , Value Loss: 1950506.5\n",
      "Episode 6900, Policy Loss: , Value Loss: 1956684.0\n",
      "Episode 6910, Policy Loss: , Value Loss: 1962079.25\n",
      "Episode 6920, Policy Loss: , Value Loss: 1968596.875\n",
      "Episode 6930, Policy Loss: , Value Loss: 1974819.125\n",
      "Episode 6940, Policy Loss: , Value Loss: 1981030.875\n",
      "Episode 6950, Policy Loss: , Value Loss: 1986984.125\n",
      "Episode 6960, Policy Loss: , Value Loss: 1992953.0\n",
      "Episode 6970, Policy Loss: , Value Loss: 1998836.5\n",
      "Episode 6980, Policy Loss: , Value Loss: 2005048.375\n",
      "Episode 6990, Policy Loss: , Value Loss: 2011340.75\n",
      "Episode 7000, Policy Loss: , Value Loss: 2017767.875\n",
      "Episode 7010, Policy Loss: , Value Loss: 2023862.625\n",
      "Episode 7020, Policy Loss: , Value Loss: 2030236.375\n",
      "Episode 7030, Policy Loss: , Value Loss: 2036653.75\n",
      "Episode 7040, Policy Loss: , Value Loss: 2042868.5\n",
      "Episode 7050, Policy Loss: , Value Loss: 2049333.375\n",
      "Episode 7060, Policy Loss: , Value Loss: 2055664.875\n",
      "Episode 7070, Policy Loss: , Value Loss: 2062439.25\n",
      "Episode 7080, Policy Loss: , Value Loss: 2069290.25\n",
      "Episode 7090, Policy Loss: , Value Loss: 2075869.875\n",
      "Episode 7100, Policy Loss: , Value Loss: 2082232.625\n",
      "Episode 7110, Policy Loss: , Value Loss: 2088774.0\n",
      "Episode 7120, Policy Loss: , Value Loss: 2095544.875\n",
      "Episode 7130, Policy Loss: , Value Loss: 2102209.0\n",
      "Episode 7140, Policy Loss: , Value Loss: 2108284.25\n",
      "Episode 7150, Policy Loss: , Value Loss: 2115029.75\n",
      "Episode 7160, Policy Loss: , Value Loss: 2121482.25\n",
      "Episode 7170, Policy Loss: , Value Loss: 2127216.5\n",
      "Episode 7180, Policy Loss: , Value Loss: 2132933.75\n",
      "Episode 7190, Policy Loss: , Value Loss: 2138513.0\n",
      "Episode 7200, Policy Loss: , Value Loss: 2145052.25\n",
      "Episode 7210, Policy Loss: , Value Loss: 2151432.75\n",
      "Episode 7220, Policy Loss: , Value Loss: 2157633.75\n",
      "Episode 7230, Policy Loss: , Value Loss: 2164206.0\n",
      "Episode 7240, Policy Loss: , Value Loss: 2170722.75\n",
      "Episode 7250, Policy Loss: , Value Loss: 2177203.0\n",
      "Episode 7260, Policy Loss: , Value Loss: 2183228.25\n",
      "Episode 7270, Policy Loss: , Value Loss: 2189394.5\n",
      "Episode 7280, Policy Loss: , Value Loss: 2195802.75\n",
      "Episode 7290, Policy Loss: , Value Loss: 2201817.0\n",
      "Episode 7300, Policy Loss: , Value Loss: 2208058.25\n",
      "Episode 7310, Policy Loss: , Value Loss: 2214417.0\n",
      "Episode 7320, Policy Loss: , Value Loss: 2220196.5\n",
      "Episode 7330, Policy Loss: , Value Loss: 2225930.5\n",
      "Episode 7340, Policy Loss: , Value Loss: 2232265.75\n",
      "Episode 7350, Policy Loss: , Value Loss: 2238205.75\n",
      "Episode 7360, Policy Loss: , Value Loss: 2243705.0\n",
      "Episode 7370, Policy Loss: , Value Loss: 2249841.25\n",
      "Episode 7380, Policy Loss: , Value Loss: 2255581.25\n",
      "Episode 7390, Policy Loss: , Value Loss: 2261733.75\n",
      "Episode 7400, Policy Loss: , Value Loss: 2267929.0\n",
      "Episode 7410, Policy Loss: , Value Loss: 2274195.25\n",
      "Episode 7420, Policy Loss: , Value Loss: 2280306.5\n",
      "Episode 7430, Policy Loss: , Value Loss: 2287041.75\n",
      "Episode 7440, Policy Loss: , Value Loss: 2293220.25\n",
      "Episode 7450, Policy Loss: , Value Loss: 2299269.5\n",
      "Episode 7460, Policy Loss: , Value Loss: 2305288.5\n",
      "Episode 7470, Policy Loss: , Value Loss: 2310383.75\n",
      "Episode 7480, Policy Loss: , Value Loss: 2315884.0\n",
      "Episode 7490, Policy Loss: , Value Loss: 2320785.0\n",
      "Episode 7500, Policy Loss: , Value Loss: 2326521.25\n",
      "Episode 7510, Policy Loss: , Value Loss: 2332494.75\n",
      "Episode 7520, Policy Loss: , Value Loss: 2338492.25\n",
      "Episode 7530, Policy Loss: , Value Loss: 2344549.5\n",
      "Episode 7540, Policy Loss: , Value Loss: 2350450.25\n",
      "Episode 7550, Policy Loss: , Value Loss: 2356444.25\n",
      "Episode 7560, Policy Loss: , Value Loss: 2362423.25\n",
      "Episode 7570, Policy Loss: , Value Loss: 2368638.75\n",
      "Episode 7580, Policy Loss: , Value Loss: 2374344.25\n",
      "Episode 7590, Policy Loss: , Value Loss: 2380953.75\n",
      "Episode 7600, Policy Loss: , Value Loss: 2387384.0\n",
      "Episode 7610, Policy Loss: , Value Loss: 2393963.25\n",
      "Episode 7620, Policy Loss: , Value Loss: 2400132.25\n",
      "Episode 7630, Policy Loss: , Value Loss: 2407166.25\n",
      "Episode 7640, Policy Loss: , Value Loss: 2414077.5\n",
      "Episode 7650, Policy Loss: , Value Loss: 2420537.5\n",
      "Episode 7660, Policy Loss: , Value Loss: 2427116.75\n",
      "Episode 7670, Policy Loss: , Value Loss: 2434264.25\n",
      "Episode 7680, Policy Loss: , Value Loss: 2441067.25\n",
      "Episode 7690, Policy Loss: , Value Loss: 2447183.5\n",
      "Episode 7700, Policy Loss: , Value Loss: 2454106.75\n",
      "Episode 7710, Policy Loss: , Value Loss: 2460453.0\n",
      "Episode 7720, Policy Loss: , Value Loss: 2467484.25\n",
      "Episode 7730, Policy Loss: , Value Loss: 2474008.25\n",
      "Episode 7740, Policy Loss: , Value Loss: 2480502.5\n",
      "Episode 7750, Policy Loss: , Value Loss: 2486834.25\n",
      "Episode 7760, Policy Loss: , Value Loss: 2493128.0\n",
      "Episode 7770, Policy Loss: , Value Loss: 2499258.75\n",
      "Episode 7780, Policy Loss: , Value Loss: 2505286.0\n",
      "Episode 7790, Policy Loss: , Value Loss: 2511658.75\n",
      "Episode 7800, Policy Loss: , Value Loss: 2518068.25\n",
      "Episode 7810, Policy Loss: , Value Loss: 2524584.0\n",
      "Episode 7820, Policy Loss: , Value Loss: 2530439.25\n",
      "Episode 7830, Policy Loss: , Value Loss: 2536717.0\n",
      "Episode 7840, Policy Loss: , Value Loss: 2542960.5\n",
      "Episode 7850, Policy Loss: , Value Loss: 2548975.75\n",
      "Episode 7860, Policy Loss: , Value Loss: 2554613.75\n",
      "Episode 7870, Policy Loss: , Value Loss: 2561053.75\n",
      "Episode 7880, Policy Loss: , Value Loss: 2567240.75\n",
      "Episode 7890, Policy Loss: , Value Loss: 2573698.25\n",
      "Episode 7900, Policy Loss: , Value Loss: 2579415.25\n",
      "Episode 7910, Policy Loss: , Value Loss: 2585516.0\n",
      "Episode 7920, Policy Loss: , Value Loss: 2590874.25\n",
      "Episode 7930, Policy Loss: , Value Loss: 2597143.0\n",
      "Episode 7940, Policy Loss: , Value Loss: 2602776.25\n",
      "Episode 7950, Policy Loss: , Value Loss: 2609020.25\n",
      "Episode 7960, Policy Loss: , Value Loss: 2614552.25\n",
      "Episode 7970, Policy Loss: , Value Loss: 2620952.0\n",
      "Episode 7980, Policy Loss: , Value Loss: 2626777.25\n",
      "Episode 7990, Policy Loss: , Value Loss: 2632784.0\n",
      "Episode 8000, Policy Loss: , Value Loss: 2639057.75\n",
      "Episode 8010, Policy Loss: , Value Loss: 2645428.0\n",
      "Episode 8020, Policy Loss: , Value Loss: 2652199.75\n",
      "Episode 8030, Policy Loss: , Value Loss: 2658512.25\n",
      "Episode 8040, Policy Loss: , Value Loss: 2664555.0\n",
      "Episode 8050, Policy Loss: , Value Loss: 2671218.25\n",
      "Episode 8060, Policy Loss: , Value Loss: 2677992.25\n",
      "Episode 8070, Policy Loss: , Value Loss: 2684956.75\n",
      "Episode 8080, Policy Loss: , Value Loss: 2691814.5\n",
      "Episode 8090, Policy Loss: , Value Loss: 2698116.5\n",
      "Episode 8100, Policy Loss: , Value Loss: 2705094.25\n",
      "Episode 8110, Policy Loss: , Value Loss: 2712264.25\n",
      "Episode 8120, Policy Loss: , Value Loss: 2718397.5\n",
      "Episode 8130, Policy Loss: , Value Loss: 2724931.0\n",
      "Episode 8140, Policy Loss: , Value Loss: 2731451.0\n",
      "Episode 8150, Policy Loss: , Value Loss: 2737429.75\n",
      "Episode 8160, Policy Loss: , Value Loss: 2744284.5\n",
      "Episode 8170, Policy Loss: , Value Loss: 2750703.25\n",
      "Episode 8180, Policy Loss: , Value Loss: 2756719.5\n",
      "Episode 8190, Policy Loss: , Value Loss: 2763618.5\n",
      "Episode 8200, Policy Loss: , Value Loss: 2769766.75\n",
      "Episode 8210, Policy Loss: , Value Loss: 2776701.25\n",
      "Episode 8220, Policy Loss: , Value Loss: 2783488.0\n",
      "Episode 8230, Policy Loss: , Value Loss: 2790478.25\n",
      "Episode 8240, Policy Loss: , Value Loss: 2797692.5\n",
      "Episode 8250, Policy Loss: , Value Loss: 2804780.0\n",
      "Episode 8260, Policy Loss: , Value Loss: 2812225.5\n",
      "Episode 8270, Policy Loss: , Value Loss: 2819298.5\n",
      "Episode 8280, Policy Loss: , Value Loss: 2827181.0\n",
      "Episode 8290, Policy Loss: , Value Loss: 2834791.25\n",
      "Episode 8300, Policy Loss: , Value Loss: 2841990.0\n",
      "Episode 8310, Policy Loss: , Value Loss: 2849485.5\n",
      "Episode 8320, Policy Loss: , Value Loss: 2856473.0\n",
      "Episode 8330, Policy Loss: , Value Loss: 2863313.75\n",
      "Episode 8340, Policy Loss: , Value Loss: 2871142.25\n",
      "Episode 8350, Policy Loss: , Value Loss: 2878446.0\n",
      "Episode 8360, Policy Loss: , Value Loss: 2886307.25\n",
      "Episode 8370, Policy Loss: , Value Loss: 2893901.25\n",
      "Episode 8380, Policy Loss: , Value Loss: 2901566.25\n",
      "Episode 8390, Policy Loss: , Value Loss: 2909592.75\n",
      "Episode 8400, Policy Loss: , Value Loss: 2917313.0\n",
      "Episode 8410, Policy Loss: , Value Loss: 2924923.25\n",
      "Episode 8420, Policy Loss: , Value Loss: 2932098.0\n",
      "Episode 8430, Policy Loss: , Value Loss: 2939494.25\n",
      "Episode 8440, Policy Loss: , Value Loss: 2946978.75\n",
      "Episode 8450, Policy Loss: , Value Loss: 2954566.25\n",
      "Episode 8460, Policy Loss: , Value Loss: 2962293.5\n",
      "Episode 8470, Policy Loss: , Value Loss: 2970468.0\n",
      "Episode 8480, Policy Loss: , Value Loss: 2977493.0\n",
      "Episode 8490, Policy Loss: , Value Loss: 2984583.75\n",
      "Episode 8500, Policy Loss: , Value Loss: 2991597.0\n",
      "Episode 8510, Policy Loss: , Value Loss: 2998999.5\n",
      "Episode 8520, Policy Loss: , Value Loss: 3005591.25\n",
      "Episode 8530, Policy Loss: , Value Loss: 3011928.25\n",
      "Episode 8540, Policy Loss: , Value Loss: 3017904.75\n",
      "Episode 8550, Policy Loss: , Value Loss: 3024850.5\n",
      "Episode 8560, Policy Loss: , Value Loss: 3031269.0\n",
      "Episode 8570, Policy Loss: , Value Loss: 3039076.25\n",
      "Episode 8580, Policy Loss: , Value Loss: 3047040.0\n",
      "Episode 8590, Policy Loss: , Value Loss: 3054637.0\n",
      "Episode 8600, Policy Loss: , Value Loss: 3061480.75\n",
      "Episode 8610, Policy Loss: , Value Loss: 3068112.75\n",
      "Episode 8620, Policy Loss: , Value Loss: 3075352.5\n",
      "Episode 8630, Policy Loss: , Value Loss: 3082423.5\n",
      "Episode 8640, Policy Loss: , Value Loss: 3089907.75\n",
      "Episode 8650, Policy Loss: , Value Loss: 3097222.75\n",
      "Episode 8660, Policy Loss: , Value Loss: 3104531.75\n",
      "Episode 8670, Policy Loss: , Value Loss: 3111992.75\n",
      "Episode 8680, Policy Loss: , Value Loss: 3119441.0\n",
      "Episode 8690, Policy Loss: , Value Loss: 3127375.25\n",
      "Episode 8700, Policy Loss: , Value Loss: 3134465.5\n",
      "Episode 8710, Policy Loss: , Value Loss: 3142117.25\n",
      "Episode 8720, Policy Loss: , Value Loss: 3149189.0\n",
      "Episode 8730, Policy Loss: , Value Loss: 3156690.5\n",
      "Episode 8740, Policy Loss: , Value Loss: 3164062.75\n",
      "Episode 8750, Policy Loss: , Value Loss: 3171353.25\n",
      "Episode 8760, Policy Loss: , Value Loss: 3179449.0\n",
      "Episode 8770, Policy Loss: , Value Loss: 3188046.0\n",
      "Episode 8780, Policy Loss: , Value Loss: 3197359.0\n",
      "Episode 8790, Policy Loss: , Value Loss: 3205708.75\n",
      "Episode 8800, Policy Loss: , Value Loss: 3214687.5\n",
      "Episode 8810, Policy Loss: , Value Loss: 3223813.5\n",
      "Episode 8820, Policy Loss: , Value Loss: 3231330.75\n",
      "Episode 8830, Policy Loss: , Value Loss: 3239981.5\n",
      "Episode 8840, Policy Loss: , Value Loss: 3247698.25\n",
      "Episode 8850, Policy Loss: , Value Loss: 3255900.25\n",
      "Episode 8860, Policy Loss: , Value Loss: 3264894.25\n",
      "Episode 8870, Policy Loss: , Value Loss: 3273294.25\n",
      "Episode 8880, Policy Loss: , Value Loss: 3282288.0\n",
      "Episode 8890, Policy Loss: , Value Loss: 3290979.75\n",
      "Episode 8900, Policy Loss: , Value Loss: 3299286.0\n",
      "Episode 8910, Policy Loss: , Value Loss: 3308180.0\n",
      "Episode 8920, Policy Loss: , Value Loss: 3316294.75\n",
      "Episode 8930, Policy Loss: , Value Loss: 3325288.75\n",
      "Episode 8940, Policy Loss: , Value Loss: 3333462.75\n",
      "Episode 8950, Policy Loss: , Value Loss: 3342596.25\n",
      "Episode 8960, Policy Loss: , Value Loss: 3350854.0\n",
      "Episode 8970, Policy Loss: , Value Loss: 3359352.0\n",
      "Episode 8980, Policy Loss: , Value Loss: 3367479.25\n",
      "Episode 8990, Policy Loss: , Value Loss: 3375365.0\n",
      "Episode 9000, Policy Loss: , Value Loss: 3383589.25\n",
      "Episode 9010, Policy Loss: , Value Loss: 3391481.75\n",
      "Episode 9020, Policy Loss: , Value Loss: 3398774.25\n",
      "Episode 9030, Policy Loss: , Value Loss: 3406305.0\n",
      "Episode 9040, Policy Loss: , Value Loss: 3413492.5\n",
      "Episode 9050, Policy Loss: , Value Loss: 3420479.25\n",
      "Episode 9060, Policy Loss: , Value Loss: 3427789.25\n",
      "Episode 9070, Policy Loss: , Value Loss: 3434688.75\n",
      "Episode 9080, Policy Loss: , Value Loss: 3442666.25\n",
      "Episode 9090, Policy Loss: , Value Loss: 3450062.5\n",
      "Episode 9100, Policy Loss: , Value Loss: 3457455.5\n",
      "Episode 9110, Policy Loss: , Value Loss: 3464164.75\n",
      "Episode 9120, Policy Loss: , Value Loss: 3470783.0\n",
      "Episode 9130, Policy Loss: , Value Loss: 3477427.25\n",
      "Episode 9140, Policy Loss: , Value Loss: 3483973.5\n",
      "Episode 9150, Policy Loss: , Value Loss: 3491386.5\n",
      "Episode 9160, Policy Loss: , Value Loss: 3498224.5\n",
      "Episode 9170, Policy Loss: , Value Loss: 3504590.5\n",
      "Episode 9180, Policy Loss: , Value Loss: 3511189.75\n",
      "Episode 9190, Policy Loss: , Value Loss: 3517179.0\n",
      "Episode 9200, Policy Loss: , Value Loss: 3524181.5\n",
      "Episode 9210, Policy Loss: , Value Loss: 3530254.5\n",
      "Episode 9220, Policy Loss: , Value Loss: 3536937.5\n",
      "Episode 9230, Policy Loss: , Value Loss: 3544009.0\n",
      "Episode 9240, Policy Loss: , Value Loss: 3550216.25\n",
      "Episode 9250, Policy Loss: , Value Loss: 3557675.25\n",
      "Episode 9260, Policy Loss: , Value Loss: 3564064.0\n",
      "Episode 9270, Policy Loss: , Value Loss: 3570925.5\n",
      "Episode 9280, Policy Loss: , Value Loss: 3578024.0\n",
      "Episode 9290, Policy Loss: , Value Loss: 3585856.25\n",
      "Episode 9300, Policy Loss: , Value Loss: 3592997.5\n",
      "Episode 9310, Policy Loss: , Value Loss: 3600643.75\n",
      "Episode 9320, Policy Loss: , Value Loss: 3607546.75\n",
      "Episode 9330, Policy Loss: , Value Loss: 3615212.5\n",
      "Episode 9340, Policy Loss: , Value Loss: 3622217.0\n",
      "Episode 9350, Policy Loss: , Value Loss: 3629752.75\n",
      "Episode 9360, Policy Loss: , Value Loss: 3637125.0\n",
      "Episode 9370, Policy Loss: , Value Loss: 3644545.5\n",
      "Episode 9380, Policy Loss: , Value Loss: 3652107.25\n",
      "Episode 9390, Policy Loss: , Value Loss: 3659982.5\n",
      "Episode 9400, Policy Loss: , Value Loss: 3667145.5\n",
      "Episode 9410, Policy Loss: , Value Loss: 3675620.25\n",
      "Episode 9420, Policy Loss: , Value Loss: 3684243.25\n",
      "Episode 9430, Policy Loss: , Value Loss: 3692221.0\n",
      "Episode 9440, Policy Loss: , Value Loss: 3701314.0\n",
      "Episode 9450, Policy Loss: , Value Loss: 3709835.5\n",
      "Episode 9460, Policy Loss: , Value Loss: 3718005.25\n",
      "Episode 9470, Policy Loss: , Value Loss: 3726527.75\n",
      "Episode 9480, Policy Loss: , Value Loss: 3735006.75\n",
      "Episode 9490, Policy Loss: , Value Loss: 3743851.0\n",
      "Episode 9500, Policy Loss: , Value Loss: 3752044.75\n",
      "Episode 9510, Policy Loss: , Value Loss: 3760170.0\n",
      "Episode 9520, Policy Loss: , Value Loss: 3768509.75\n",
      "Episode 9530, Policy Loss: , Value Loss: 3776722.5\n",
      "Episode 9540, Policy Loss: , Value Loss: 3784332.25\n",
      "Episode 9550, Policy Loss: , Value Loss: 3791271.75\n",
      "Episode 9560, Policy Loss: , Value Loss: 3798729.25\n",
      "Episode 9570, Policy Loss: , Value Loss: 3805985.5\n",
      "Episode 9580, Policy Loss: , Value Loss: 3813557.25\n",
      "Episode 9590, Policy Loss: , Value Loss: 3821493.25\n",
      "Episode 9600, Policy Loss: , Value Loss: 3829143.75\n",
      "Episode 9610, Policy Loss: , Value Loss: 3836089.5\n",
      "Episode 9620, Policy Loss: , Value Loss: 3844686.75\n",
      "Episode 9630, Policy Loss: , Value Loss: 3852509.5\n",
      "Episode 9640, Policy Loss: , Value Loss: 3861278.5\n",
      "Episode 9650, Policy Loss: , Value Loss: 3869249.5\n",
      "Episode 9660, Policy Loss: , Value Loss: 3878341.75\n",
      "Episode 9670, Policy Loss: , Value Loss: 3886115.75\n",
      "Episode 9680, Policy Loss: , Value Loss: 3894046.5\n",
      "Episode 9690, Policy Loss: , Value Loss: 3901961.5\n",
      "Episode 9700, Policy Loss: , Value Loss: 3909967.25\n",
      "Episode 9710, Policy Loss: , Value Loss: 3917887.25\n",
      "Episode 9720, Policy Loss: , Value Loss: 3926106.25\n",
      "Episode 9730, Policy Loss: , Value Loss: 3935212.0\n",
      "Episode 9740, Policy Loss: , Value Loss: 3943397.25\n",
      "Episode 9750, Policy Loss: , Value Loss: 3951415.5\n",
      "Episode 9760, Policy Loss: , Value Loss: 3960398.75\n",
      "Episode 9770, Policy Loss: , Value Loss: 3968801.75\n",
      "Episode 9780, Policy Loss: , Value Loss: 3978376.75\n",
      "Episode 9790, Policy Loss: , Value Loss: 3987726.5\n",
      "Episode 9800, Policy Loss: , Value Loss: 3996817.75\n",
      "Episode 9810, Policy Loss: , Value Loss: 4005511.75\n",
      "Episode 9820, Policy Loss: , Value Loss: 4014875.25\n",
      "Episode 9830, Policy Loss: , Value Loss: 4023489.75\n",
      "Episode 9840, Policy Loss: , Value Loss: 4032174.75\n",
      "Episode 9850, Policy Loss: , Value Loss: 4041095.75\n",
      "Episode 9860, Policy Loss: , Value Loss: 4049358.25\n",
      "Episode 9870, Policy Loss: , Value Loss: 4057990.0\n",
      "Episode 9880, Policy Loss: , Value Loss: 4066180.0\n",
      "Episode 9890, Policy Loss: , Value Loss: 4075154.75\n",
      "Episode 9900, Policy Loss: , Value Loss: 4082848.75\n",
      "Episode 9910, Policy Loss: , Value Loss: 4090681.5\n",
      "Episode 9920, Policy Loss: , Value Loss: 4098736.75\n",
      "Episode 9930, Policy Loss: , Value Loss: 4107230.25\n",
      "Episode 9940, Policy Loss: , Value Loss: 4115026.75\n",
      "Episode 9950, Policy Loss: , Value Loss: 4123311.25\n",
      "Episode 9960, Policy Loss: , Value Loss: 4131750.75\n",
      "Episode 9970, Policy Loss: , Value Loss: 4140566.0\n",
      "Episode 9980, Policy Loss: , Value Loss: 4148408.5\n",
      "Episode 9990, Policy Loss: , Value Loss: 4155768.0\n"
     ]
    }
   ],
   "source": [
    "from math import e\n",
    "import time\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "# Define paths to save and load the models\n",
    "policy_model_path = 'policy_model.pth'\n",
    "value_model_path = 'value_model.pth'\n",
    "backup_directory = '/content/drive/My Drive/Colab Notebooks/Oomi Backups' # Replace with your path\n",
    "csv_path = 'dataset/'\n",
    "\n",
    "# Initialize the models and optimizers\n",
    "input_dim = 104\n",
    "hidden_dim = 128\n",
    "output_dim = 32\n",
    "num_layers = 2\n",
    "batch_size = 999\n",
    "\n",
    "clip_param = 0.2  # PPO clipping parameter\n",
    "entropy_coef = 0.01  # Entropy coefficient\n",
    "\n",
    "\n",
    "# Initialize Replay Buffer\n",
    "replay_buffer = ReplayBuffer(capacity=1000)  # Adjust capacity as needed\n",
    "\n",
    "# policy_net = LSTMModel(input_dim, hidden_dim, output_dim)\n",
    "# value_net = LSTMModel(input_dim, hidden_dim, output_dim, is_value_net=True)\n",
    "\n",
    "# Load existing models if available, otherwise create new ones\n",
    "if os.path.exists(\"/kaggle/input/rl-oomicardmodel/pytorch/v3.0.0/1/policy_model.pth\"):\n",
    "    print(\"loading exist policy model\")\n",
    "    policy_net = torch.load(\"/kaggle/input/rl-oomicardmodel/pytorch/v3.0.0/1/policy_model.pth\")\n",
    "else:\n",
    "    print(\"creating new policy model\")\n",
    "    policy_net = PolicyNetwork(input_dim, hidden_dim, num_layers, output_dim, dropout=0.5)\n",
    "\n",
    "\n",
    "if os.path.exists(\"/kaggle/input/rl-oomicardmodel/pytorch/v3.0.0/1/value_model.pth\"):\n",
    "    print(\"loading exist value model\")\n",
    "    value_net = torch.load(\"/kaggle/input/rl-oomicardmodel/pytorch/v3.0.0/1/value_model.pth\")\n",
    "else:\n",
    "    print(\"creating new value model\")\n",
    "    value_net = ValueNetwork(input_dim, hidden_dim, num_layers, dropout=0.5)\n",
    "    \n",
    "policy_net.to(\"cuda\")\n",
    "value_net.to(\"cuda\")\n",
    "\n",
    "# Open CSV file and write header\n",
    "csv_file_path = os.path.join(csv_path, 'training_data.csv')\n",
    "os.makedirs(csv_path, exist_ok=True)\n",
    "    \n",
    "env = OomiEnvironment(policy_net, value_net)\n",
    "policy_optimizer = optim.Adam(policy_net.parameters(), lr=1e-3)\n",
    "value_optimizer = optim.Adam(value_net.parameters(), lr=1e-3)\n",
    "\n",
    "with open(csv_file_path, mode='a+', newline='') as csv_file:\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "    csv_writer.writerow(['PlayerID', 'State', 'Action', 'Reward', 'Done', 'Action Prob'])\n",
    "\n",
    "    # Training loop\n",
    "    num_episodes = 10000\n",
    "    gamma = 0.99\n",
    "\n",
    "    for episode in range(num_episodes):\n",
    "        # Reset hidden states for all players\n",
    "        for player in env.players:\n",
    "            player.reset_hidden()\n",
    "\n",
    "        desk = env.reset()\n",
    "        done = False\n",
    "        states = [[] for _ in range(4)]\n",
    "        actions = [[] for _ in range(4)]\n",
    "        rewards = [[] for _ in range(4)]\n",
    "        action_probs = [[] for _ in range(4)]\n",
    "\n",
    "        for _ in range(8):\n",
    "            r_done = False\n",
    "            r_rewards = [[] for _ in range(4)]\n",
    "            for id in range(4):\n",
    "                state, action, reward, r_done, done, action_prob = env.players[id].play()\n",
    "                states[id].append(state.tolist())\n",
    "                actions[id].append(action)\n",
    "                r_rewards[id].append(reward)\n",
    "                action_probs[id].append(action_prob)\n",
    "\n",
    "                # Write step data to CSV\n",
    "                csv_writer.writerow([id, state.tolist(), action, reward, done, action_prob])\n",
    "\n",
    "            r_rewards = env.prep_rewards(r_rewards)\n",
    "            for i in range(4):\n",
    "                rewards[i].extend(r_rewards[i])\n",
    "            env.reset_round()\n",
    "\n",
    "        # Add some overall rewards\n",
    "        for i in range(4):\n",
    "            env.p_rewards[i] = env.team_score[i % 2]\n",
    "\n",
    "        rewards = env.prep_rewards(rewards)\n",
    "\n",
    "        for i in range(4):\n",
    "            replay_buffer.push(torch.tensor(states[i], dtype=torch.float32).squeeze(1),\n",
    "                               torch.tensor(actions[i], dtype=torch.int),\n",
    "                               torch.tensor(rewards[i], dtype=torch.float32),\n",
    "                               torch.tensor(action_probs[0][i], dtype=torch.float32))\n",
    "            \n",
    "\n",
    "        # Sample from the replay buffer and update the networks\n",
    "        if len(replay_buffer) > batch_size:\n",
    "            policy_losses = []\n",
    "            value_losses = []\n",
    "            \n",
    "            for states, actions, rewards, old_action_probs in replay_buffer.sample(batch_size):\n",
    "                sample_size = states.size(0)\n",
    "\n",
    "                # Policy Network Forward Pass\n",
    "#                 policy_hidden = policy_net.init_hidden(sample_size)\n",
    "#                 action_probs, policy_hidden = policy_net(states, policy_hidden)\n",
    "#                 selected_action_probs = action_probs[np.arange(sample_size), actions]\n",
    "\n",
    "                # Value Network Forward Pass\n",
    "                value_hidden = value_net.init_hidden(sample_size)\n",
    "                state_values, value_hidden = value_net(states, value_hidden)\n",
    "                state_values = state_values.squeeze()\n",
    "\n",
    "#                 advantages = rewards - state_values\n",
    "\n",
    "                # Compute policy loss with PPO clipped objective\n",
    "#                 ratio = selected_action_probs / (old_action_probs + 1e-8)\n",
    "#                 surr1 = ratio * advantages\n",
    "#                 surr2 = torch.clamp(ratio, 1.0 - clip_param, 1.0 + clip_param) * advantages\n",
    "#                 policy_loss = -torch.mean(torch.min(surr1, surr2)) + entropy_coef * -torch.mean(selected_action_probs * torch.log(selected_action_probs + 1e-8))\n",
    "                \n",
    "                # Compute value loss\n",
    "                value_loss = F.mse_loss(state_values, rewards)\n",
    "\n",
    "#                 policy_losses.append(policy_loss.item())\n",
    "                value_losses.append(value_loss.item())\n",
    "\n",
    "#                 total_loss = policy_loss + value_loss\n",
    "                \n",
    "\n",
    "#                 policy_optimizer.zero_grad()\n",
    "                value_optimizer.zero_grad()\n",
    "\n",
    "#                 total_loss.backward()\n",
    "                value_loss\n",
    "                # Gradient clipping\n",
    "#                 torch.nn.utils.clip_grad_norm_(policy_net.parameters(), 0.5)\n",
    "                torch.nn.utils.clip_grad_norm_(value_net.parameters(), 0.5)\n",
    "\n",
    "#                 policy_optimizer.step()\n",
    "                value_optimizer.step()\n",
    "\n",
    "#             policy_loss_mean = torch.mean(torch.tensor(policy_losses, dtype=torch.float32))\n",
    "            value_loss_mean = torch.mean(torch.tensor(value_losses, dtype=torch.float32))\n",
    "\n",
    "#             writer.add_scalar(\"Loss/policy\", policy_loss_mean.item(), episode)\n",
    "            writer.add_scalar(\"Loss/value\", value_loss_mean.item(), episode)\n",
    "\n",
    "        # Save the models after each episode\n",
    "#         torch.save(policy_net, policy_model_path)\n",
    "        torch.save(value_net, value_model_path)\n",
    "        # os.makedirs(backup_directory, exist_ok=True)\n",
    "        # torch.save(policy_net, os.path.join(backup_directory, f'policy_model.pth'))\n",
    "        # torch.save(value_net, os.path.join(backup_directory, f'value_model.pth'))\n",
    "\n",
    "        try:\n",
    "            if episode % 10 == 0:\n",
    "                print(f'Episode {episode}, Policy Loss: , Value Loss: {value_loss_mean.item()}')\n",
    "        except NameError:\n",
    "            pass\n",
    "\n",
    "\n",
    "writer.flush()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b55e7f30",
   "metadata": {
    "_cell_guid": "5992ab16-84d4-4ba5-b246-2d3bf08976c0",
    "_uuid": "0455198c-69d0-429c-9b7e-a84eb7a9aa5c",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-07-11T09:38:07.722781Z",
     "iopub.status.busy": "2024-07-11T09:38:07.722416Z",
     "iopub.status.idle": "2024-07-11T09:38:07.726448Z",
     "shell.execute_reply": "2024-07-11T09:38:07.725625Z"
    },
    "executionInfo": {
     "elapsed": 5983,
     "status": "ok",
     "timestamp": 1720201717546,
     "user": {
      "displayName": "J. V. G. Ransika",
      "userId": "13058150827256079313"
     },
     "user_tz": -330
    },
    "id": "TqWKsKhe-1OK",
    "jupyter": {
     "outputs_hidden": false
    },
    "outputId": "8e757726-2bca-4f9e-fa96-7a5678e44a8a",
    "papermill": {
     "duration": 0.086445,
     "end_time": "2024-07-11T09:38:07.728310",
     "exception": false,
     "start_time": "2024-07-11T09:38:07.641865",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %tensorboard --logdir runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505873f8",
   "metadata": {
    "papermill": {
     "duration": 0.079846,
     "end_time": "2024-07-11T09:38:07.888199",
     "exception": false,
     "start_time": "2024-07-11T09:38:07.808353",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b53b309",
   "metadata": {
    "_cell_guid": "f0449e93-63b8-4fd6-a7b3-98718d00ec8f",
    "_uuid": "2027cf31-36e8-442a-a2d4-ff8f015ca73f",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-07-11T09:38:08.049386Z",
     "iopub.status.busy": "2024-07-11T09:38:08.049072Z",
     "iopub.status.idle": "2024-07-11T09:38:08.053086Z",
     "shell.execute_reply": "2024-07-11T09:38:08.052204Z"
    },
    "id": "JFWapSOKB7ZE",
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.08664,
     "end_time": "2024-07-11T09:38:08.055109",
     "exception": false,
     "start_time": "2024-07-11T09:38:07.968469",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !rm -rf /kaggle/working/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d11ed311",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-11T09:38:08.214196Z",
     "iopub.status.busy": "2024-07-11T09:38:08.213873Z",
     "iopub.status.idle": "2024-07-11T09:38:08.217735Z",
     "shell.execute_reply": "2024-07-11T09:38:08.216908Z"
    },
    "papermill": {
     "duration": 0.08544,
     "end_time": "2024-07-11T09:38:08.219580",
     "exception": false,
     "start_time": "2024-07-11T09:38:08.134140",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ! cp /kaggle/input/rl-oomicardmodel/pytorch/v3.0.0/1/dataset/training_data.csv /kaggle/working/dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7185fa3c",
   "metadata": {
    "papermill": {
     "duration": 0.078693,
     "end_time": "2024-07-11T09:38:08.377727",
     "exception": false,
     "start_time": "2024-07-11T09:38:08.299034",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "",
   "version": ""
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30732,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 11214.165893,
   "end_time": "2024-07-11T09:38:11.890641",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-07-11T06:31:17.724748",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
